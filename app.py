import io
import re
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="ç™¾å¤§å»ºå•†ï½œé—œä¿‚éˆåˆ†æå„€è¡¨æ¿ï¼ˆè‡ªå‹•ç‰ˆï¼‰", page_icon="ğŸ—ï¸", layout="wide")
st.title("ğŸ—ï¸ ç™¾å¤§å»ºå•†ï½œé—œä¿‚éˆåˆ†æå„€è¡¨æ¿ï¼ˆè‡ªå‹•ç‰ˆï¼‰")
st.caption("ä¸Šå‚³ Excel/CSV â†’ è‡ªå‹•æ¬„ä½è¾¨è­˜ â†’ é—œä¿‚æ‹†è§£èˆ‡é…æ¯” â†’ å¤šè¦–è§’å„€è¡¨æ¿")

# ====================== Helpers ======================
@st.cache_data
def read_any(file):
    if file.name.lower().endswith(".csv"):
        return pd.read_csv(file)
    else:
        return pd.read_excel(file, engine="openpyxl")

def coerce_num(s):
    if s is None:
        return np.nan
    if isinstance(s, (int, float, np.number)):
        return s
    s = str(s).replace(",", "").replace("%", "").strip()
    if s in ("", "nan", "None"):
        return np.nan
    try:
        return float(s)
    except Exception:
        return np.nan

def normalize_ratio(series):
    s = series.apply(coerce_num)
    if s.max(skipna=True) is not None and s.max(skipna=True) > 1.000001:
        return s / 100.0
    return s

def try_pick(cols, candidates):
    for c in candidates:
        if c in cols:
            return c
    # fuzzy contains
    for c in cols:
        if any(key in str(c) for key in candidates):
            return c
    return None

def fmt_num(x, digits=2):
    if pd.isna(x):
        return "-"
    return f"{x:,.{digits}f}"

# ====================== Upload ======================
file = st.file_uploader(
    "ä¸Šå‚³ Excel æˆ– CSV æª”ï¼ˆä¸æä¾›å´é‚Šæ“ä½œï¼Œç³»çµ±å°‡è‡ªå‹•åˆ†æï¼‰",
    type=["xlsx", "xls", "csv"],
    help="æœ€å¤š 200 MBï¼›Excel éœ€ä½¿ç”¨ openpyxl è§£æ",
)

if not file:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
    st.stop()

df_raw = read_any(file)
cols = df_raw.columns.tolist()

# ====================== Auto column detection ======================
dev_col = try_pick(cols, ["å»ºå•†", "å»ºè¨­å…¬å¸", "å»ºè¨­å…¬å¸(æ¥­ä¸»)"])
con_col = try_pick(cols, ["ç‡Ÿé€ å…¬å¸", "ç‡Ÿé€ å•†"])
mep_col = try_pick(cols, ["æ°´é›»å…¨å", "æ°´é›»å…¬å¸", "æ©Ÿé›»å…¬å¸", "æ©Ÿé›»å» å•†"])
vol_col = try_pick(cols, ["å¹´ä½¿ç”¨é‡/è¬", "å¹´ä½¿ç”¨é‡(è¬)", "ç”¨é‡_è¬"])

dA_col = try_pick(cols, ["ç¶“éŠ·å•†A", "ç¶“éŠ·A", "ç¶“éŠ·å•†1"])
rA_col = try_pick(cols, ["ç¶“éŠ·Aä½”æ¯”(%)", "ç¶“éŠ·å•†Aé…æ¯”", "Aé…æ¯”"])
dB_col = try_pick(cols, ["ç¶“éŠ·å•†B", "ç¶“éŠ·B", "ç¶“éŠ·å•†2"])
rB_col = try_pick(cols, ["ç¶“éŠ·Bä½”æ¯”(%)", "ç¶“éŠ·å•†Bé…æ¯”", "Bé…æ¯”"])
dC_col = try_pick(cols, ["ç¶“éŠ·å•†C", "ç¶“éŠ·ï¼£", "ç¶“éŠ·å•†3"])
rC_col = try_pick(cols, ["ç¶“éŠ·ï¼£ä½”æ¯”(%)", "ç¶“éŠ·Cä½”æ¯”(%)", "ç¶“éŠ·å•†Cé…æ¯”", "Cé…æ¯”"])

with st.expander("ğŸ” æ¬„ä½è‡ªå‹•è¾¨è­˜çµæœï¼ˆåƒ…é¡¯ç¤ºï¼Œä¸å¯æ“ä½œï¼‰", expanded=True):
    st.write(pd.DataFrame({
        "è§’è‰²": ["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡(è¬)","ç¶“éŠ·A","é…æ¯”A","ç¶“éŠ·B","é…æ¯”B","ç¶“éŠ·C","é…æ¯”C"],
        "å°æ‡‰æ¬„ä½": [dev_col, con_col, mep_col, vol_col, dA_col, rA_col, dB_col, rB_col, dC_col, rC_col]
    }))

required = [dev_col, con_col, mep_col, vol_col]
missing = [r for r, c in zip(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡(è¬)"], required) if c is None]
if missing:
    st.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{', '.join(missing)}ã€‚è«‹ç¢ºèªè³‡æ–™è¡¨æ¬„åã€‚")
    st.stop()

# ====================== Transform ======================
df = df_raw.rename(columns={
    dev_col: "å»ºè¨­å…¬å¸", con_col: "ç‡Ÿé€ å…¬å¸", mep_col: "æ°´é›»å…¬å¸", vol_col: "å¹´ä½¿ç”¨é‡_è¬",
    dA_col or "ç¶“éŠ·å•†A": "ç¶“éŠ·å•†A", rA_col or "ç¶“éŠ·Aä½”æ¯”(%)": "ç¶“éŠ·Aæ¯”",
    dB_col or "ç¶“éŠ·å•†B": "ç¶“éŠ·å•†B", rB_col or "ç¶“éŠ·Bä½”æ¯”(%)": "ç¶“éŠ·Bæ¯”",
    dC_col or "ç¶“éŠ·å•†C": "ç¶“éŠ·å•†C", rC_col or "ç¶“éŠ·ï¼£ä½”æ¯”(%)": "ç¶“éŠ·Cæ¯”",
}).copy()

df["å¹´ä½¿ç”¨é‡_è¬"] = df["å¹´ä½¿ç”¨é‡_è¬"].apply(coerce_num)
for c in ["ç¶“éŠ·Aæ¯”","ç¶“éŠ·Bæ¯”","ç¶“éŠ·Cæ¯”"]:
    if c in df.columns:
        df[c] = normalize_ratio(df[c])

dealer_blocks = []
if "ç¶“éŠ·å•†A" in df.columns and "ç¶“éŠ·Aæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†A","ç¶“éŠ·Aæ¯”"]].rename(columns={"ç¶“éŠ·å•†A":"ç¶“éŠ·å•†","ç¶“éŠ·Aæ¯”":"é…æ¯”"}))
if "ç¶“éŠ·å•†B" in df.columns and "ç¶“éŠ·Bæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†B","ç¶“éŠ·Bæ¯”"]].rename(columns={"ç¶“éŠ·å•†B":"ç¶“éŠ·å•†","ç¶“éŠ·Bæ¯”":"é…æ¯”"}))
if "ç¶“éŠ·å•†C" in df.columns and "ç¶“éŠ·Cæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†C","ç¶“éŠ·Cæ¯”"]].rename(columns={"ç¶“éŠ·å•†C":"ç¶“éŠ·å•†","ç¶“éŠ·Cæ¯”":"é…æ¯”"}))

rel = pd.concat(dealer_blocks, ignore_index=True) if dealer_blocks else pd.DataFrame(columns=["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†","é…æ¯”"])
rel["ç¶“éŠ·å•†"] = rel["ç¶“éŠ·å•†"].replace({0: np.nan, "0": np.nan, "": np.nan}).astype("string")
rel = rel.dropna(subset=["ç¶“éŠ·å•†"]).copy()
rel["æ‰¿æ¥é‡_è¬"] = rel["å¹´ä½¿ç”¨é‡_è¬"] * rel["é…æ¯”"]
rel["æ‰¿æ¥é‡_å…ƒ"] = rel["æ‰¿æ¥é‡_è¬"] * 10000

# é…æ¯”æª¢æŸ¥
ratio_check = rel.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], dropna=False)["é…æ¯”"].sum().reset_index()
ratio_check["é…æ¯”åˆè¨ˆ"] = ratio_check["é…æ¯”"]
ratio_check["æ˜¯å¦=1(Â±0.01)"] = np.isclose(ratio_check["é…æ¯”åˆè¨ˆ"], 1.0, atol=0.01)

# é¢¨éšªæ¨™ç±¤
risk = ratio_check.copy()
risk["æ¨™ç±¤"] = np.where(~risk["æ˜¯å¦=1(Â±0.01)"], "é…æ¯”æœªé½Š", "")
# å–®ä¸€ç¶“éŠ·å•†ä¾è³´åº¦
single_dep = (rel.groupby(["æ°´é›»å…¬å¸","ç¶“éŠ·å•†"], dropna=False)["é…æ¯”"].sum().reset_index())
top_ratio = single_dep.sort_values(["æ°´é›»å…¬å¸","é…æ¯”"], ascending=[True, False]).groupby("æ°´é›»å…¬å¸").head(1)
top_ratio["å–®ä¸€ä¾è³´>80%"] = top_ratio["é…æ¯”"] >= 0.8

# ====================== Tabs ======================
tab_raw, tab_dash = st.tabs(["ğŸ“„ åŸå§‹è³‡æ–™", "ğŸ“Š åˆ†æå„€è¡¨æ¿ï¼ˆè‡ªå‹•ï¼‰"])

with tab_raw:
    st.subheader("åŸå§‹è³‡æ–™é è¦½")
    st.dataframe(df_raw, use_container_width=True)
    st.caption("æ­¤åˆ†é åƒ…é¡¯ç¤ºä½ ä¸Šå‚³çš„åŸå§‹å…§å®¹ï¼ˆæœªæ‹†åˆ†ç¶“éŠ·å•†/æœªè¨ˆç®—ï¼‰ã€‚")

with tab_dash:
    # ===== KPIs =====
    st.subheader("ç¸½è¦½ KPI")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("å»ºè¨­å…¬å¸æ•¸", f"{rel['å»ºè¨­å…¬å¸'].nunique()}")
    c2.metric("ç‡Ÿé€ å…¬å¸æ•¸", f"{rel['ç‡Ÿé€ å…¬å¸'].nunique()}")
    c3.metric("æ°´é›»å…¬å¸æ•¸", f"{rel['æ°´é›»å…¬å¸'].nunique()}")
    c4.metric("ç¶“éŠ·å•†æ‰¿æ¥ç¸½é‡(è¬å…ƒ)", fmt_num(rel['æ‰¿æ¥é‡_è¬'].sum(), 0))

    st.markdown("---")

    # ===== Analyses =====
    a1, a2 = st.columns([2,1])
    with a1:
        st.subheader("TOP ç¶“éŠ·å•†æ‰¿æ¥é‡ (å‰20)")
        dea_rank = (rel.groupby("ç¶“éŠ·å•†", dropna=False)["æ‰¿æ¥é‡_è¬"]
                    .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False).head(20))
        fig = px.bar(dea_rank, x="ç¶“éŠ·å•†", y="æ‰¿æ¥é‡_è¬", title="ç¶“éŠ·å•†æ‰¿æ¥é‡(è¬å…ƒ)")
        st.plotly_chart(fig, use_container_width=True)
    with a2:
        st.subheader("ç¶“éŠ·å•†å¸‚å ´å æ¯”")
        share = (rel.groupby("ç¶“éŠ·å•†", dropna=False)["æ‰¿æ¥é‡_è¬"]
                 .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False))
        fig = px.pie(share, names="ç¶“éŠ·å•†", values="æ‰¿æ¥é‡_è¬", title="æ‰¿æ¥é‡å æ¯”")
        st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")

    b1, b2 = st.columns(2)
    with b1:
        st.subheader("TOP æ°´é›»å…¬å¸ï¼ˆåŠ æ¬Šä½¿ç”¨é‡ï¼‰")
        mep_rank = (rel.groupby("æ°´é›»å…¬å¸", dropna=False)["æ‰¿æ¥é‡_è¬"]
                    .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False).head(20))
        fig = px.bar(mep_rank, x="æ°´é›»å…¬å¸", y="æ‰¿æ¥é‡_è¬", title="æ°´é›»å…¬å¸åŠ æ¬Šå¾Œä½¿ç”¨é‡(è¬å…ƒ)")
        st.plotly_chart(fig, use_container_width=True)
    with b2:
        st.subheader("å»ºè¨­/ç‡Ÿé€ è²¢ç»åº¦")
        t1, t2 = st.tabs(["å»ºè¨­å…¬å¸è²¢ç»", "ç‡Ÿé€ å…¬å¸è²¢ç»"])
        with t1:
            dev_rank = (rel.groupby("å»ºè¨­å…¬å¸", dropna=False)["æ‰¿æ¥é‡_è¬"]
                        .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False))
            fig = px.bar(dev_rank, x="å»ºè¨­å…¬å¸", y="æ‰¿æ¥é‡_è¬", title="å»ºè¨­å…¬å¸å¸¶ä¾†çš„åŠ æ¬Šä½¿ç”¨é‡(è¬å…ƒ)")
            st.plotly_chart(fig, use_container_width=True)
        with t2:
            con_rank = (rel.groupby("ç‡Ÿé€ å…¬å¸", dropna=False)["æ‰¿æ¥é‡_è¬"]
                        .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False))
            fig = px.bar(con_rank, x="ç‡Ÿé€ å…¬å¸", y="æ‰¿æ¥é‡_è¬", title="ç‡Ÿé€ å…¬å¸å¸¶ä¾†çš„åŠ æ¬Šä½¿ç”¨é‡(è¬å…ƒ)")
            st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")

    st.subheader("ç¶“éŠ·å•†ç«¶åˆç†±åº¦ï¼ˆåŒæ°´é›»çš„é…æ¯”åˆ†æ•£åº¦ï¼‰")
    comp = (rel.groupby(["æ°´é›»å…¬å¸", "ç¶“éŠ·å•†"], dropna=False)["é…æ¯”"]
            .sum().reset_index())
    pivot = comp.pivot(index="æ°´é›»å…¬å¸", columns="ç¶“éŠ·å•†", values="é…æ¯”").fillna(0.0)
    st.dataframe(pivot, use_container_width=True)
    st.caption("æ•¸å€¼ç‚ºé…æ¯”(0~1)ï¼Œè¡Œå…§åŠ ç¸½æ‡‰ â‰ˆ 1ã€‚è¡Œå…§è¶Šå¹³å‡ï¼Œä»£è¡¨ç«¶çˆ­è¶Šæ¿€çƒˆã€‚")

    st.markdown("---")

    st.subheader("é¢¨éšªé›·é”")
    cA, cB = st.columns(2)
    with cA:
        st.markdown("**é…æ¯”æª¢æŸ¥ï¼ˆé 1 çš„æ°´é›»å…¬å¸ï¼‰**")
        bad = ratio_check[~ratio_check["æ˜¯å¦=1(Â±0.01)"]].copy()
        if bad.empty:
            st.success("æ‰€æœ‰æ°´é›»å…¬å¸é…æ¯”åŠ ç¸½çš† â‰ˆ 1ã€‚")
        else:
            st.dataframe(bad.sort_values("é…æ¯”åˆè¨ˆ"), use_container_width=True)
    with cB:
        st.markdown("**å–®ä¸€ç¶“éŠ·å•†ä¾è³´åº¦ > 80%**")
        risky = top_ratio[top_ratio["å–®ä¸€ä¾è³´>80%"]].copy()
        if risky.empty:
            st.success("ç„¡å–®ä¸€ä¾è³´åº¦è¶…é 80% çš„æ°´é›»å…¬å¸ã€‚")
        else:
            st.dataframe(risky[["æ°´é›»å…¬å¸","ç¶“éŠ·å•†","é…æ¯”","å–®ä¸€ä¾è³´>80%"]], use_container_width=True)

    st.markdown("---")

    st.subheader("é—œä¿‚æµå‘åœ–ï¼ˆå»ºè¨­â†’ç‡Ÿé€ â†’æ°´é›»â†’ç¶“éŠ·ï¼‰")
    devs = rel["å»ºè¨­å…¬å¸"].dropna().unique().tolist()
    cons = rel["ç‡Ÿé€ å…¬å¸"].dropna().unique().tolist()
    meps = rel["æ°´é›»å…¬å¸"].dropna().unique().tolist()
    deas = rel["ç¶“éŠ·å•†"].dropna().unique().tolist()

    nodes = (
        [f"å»ºè¨­ï½œ{d}" for d in devs] +
        [f"ç‡Ÿé€ ï½œ{c}" for c in cons] +
        [f"æ°´é›»ï½œ{m}" for m in meps] +
        [f"ç¶“éŠ·ï½œ{d}" for d in deas]
    )
    node_index = {name: i for i, name in enumerate(nodes)}

    # å»ºè¨­->ç‡Ÿé€ 
    s1, t1_, v1 = [], [], []
    link1 = (rel.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index())
    for _, r in link1.iterrows():
        s1.append(node_index[f"å»ºè¨­ï½œ{r['å»ºè¨­å…¬å¸']}"])
        t1_.append(node_index[f"ç‡Ÿé€ ï½œ{r['ç‡Ÿé€ å…¬å¸']}"])
        v1.append(max(r["æ‰¿æ¥é‡_è¬"], 0))

    # ç‡Ÿé€ ->æ°´é›»
    s2, t2_, v2 = [], [], []
    link2 = (rel.groupby(["ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index())
    for _, r in link2.iterrows():
        s2.append(node_index[f"ç‡Ÿé€ ï½œ{r['ç‡Ÿé€ å…¬å¸']}"])
        t2_.append(node_index[f"æ°´é›»ï½œ{r['æ°´é›»å…¬å¸']}"])
        v2.append(max(r["æ‰¿æ¥é‡_è¬"], 0))

    # æ°´é›»->ç¶“éŠ·
    s3, t3_, v3 = [], [], []
    link3 = (rel.groupby(["æ°´é›»å…¬å¸","ç¶“éŠ·å•†"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index())
    for _, r in link3.iterrows():
        s3.append(node_index[f"æ°´é›»ï½œ{r['æ°´é›»å…¬å¸']}"])
        t3_.append(node_index[f"ç¶“éŠ·ï½œ{r['ç¶“éŠ·å•†']}"])
        v3.append(max(r["æ‰¿æ¥é‡_è¬"], 0))

    source = s1 + s2 + s3
    target = t1_ + t2_ + t3_
    value  = v1 + v2 + v3

    if len(source) == 0:
        st.info("è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç”Ÿæˆé—œä¿‚æµã€‚")
    else:
        fig = go.Figure(data=[go.Sankey(
            node=dict(pad=12, thickness=20, line=dict(width=0.5), label=nodes),
            link=dict(source=source, target=target, value=value)
        )])
        fig.update_layout(title_text="å»ºè¨­â†’ç‡Ÿé€ â†’æ°´é›»â†’ç¶“éŠ· é—œä¿‚æµï¼ˆæ‰¿æ¥é‡_è¬ï¼‰", font_size=12)
        st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")
    st.subheader("åŒ¯å‡º")
    csv_bytes = rel.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ä¸‹è¼‰ é—œä¿‚æ˜ç´° CSVï¼ˆæœªç¯©é¸ï¼‰", data=csv_bytes, file_name="relations_detail.csv", mime="text/csv")

    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df_raw.to_excel(writer, index=False, sheet_name="åŸå§‹è³‡æ–™")
        rel.to_excel(writer, index=False, sheet_name="é—œä¿‚æ˜ç´°")
        ratio_check.to_excel(writer, index=False, sheet_name="é…æ¯”æª¢æŸ¥")
        top_ratio.to_excel(writer, index=False, sheet_name="å–®ä¸€ä¾è³´æª¢æŸ¥")
    st.download_button(
        "ä¸‹è¼‰ Excelï¼ˆå¤šå·¥ä½œè¡¨ï¼‰",
        data=output.getvalue(),
        file_name="relations_dashboard_auto.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )


