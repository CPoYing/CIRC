# app.py ï¼ ç™¾å¤§å»ºå•†ï½œé—œä¿‚éˆåˆ†æï¼ˆå–®é æœå°‹ v10ï¼‰
# æ›´æ–°è¦é»ï¼š
# - å»ºè¨­å…¬å¸ï¼šç§»é™¤ç«¶çˆ­è€…åŠŸèƒ½ï¼›æ¦‚è¦½ã€Œæ¬¡æ•¸ã€æ¬„åæ”¹ã€Œåˆä½œæ¬¡æ•¸ã€ï¼›ç¶“éŠ·å•†å€å¡Šæ”¹åã€Œçµ‚ç«¯ç¶“éŠ·å•†ã€
# - æ°´é›»å…¬å¸ï¼šåˆä½œå°è±¡é¡¯ç¤ºé ä¼°å¹´ä½¿ç”¨é‡ï¼›åœ–è¡¨ä»¥é‡‘é¡(é…æ¯”Ã—å¹´ç”¨é‡)ä½œç‚ºåœ“é¤…å€¼
# - ç¶“éŠ·å•†ï¼šç«¶çˆ­è€…å€å¡Šæ–°å¢ã€Œå»é‡å¾Œæ•´é«”è¢«ç«¶çˆ­è¦†è“‹ç‡ã€(Union overlapâ‰¤100%)

import io
import re
import math
from decimal import Decimal, ROUND_HALF_UP
from collections import defaultdict
from pathlib import Path
from datetime import datetime

import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px

# ====================== åŸºæœ¬è¨­å®šèˆ‡æ¨£å¼ ======================
st.set_page_config(page_title="ç™¾å¤§å»ºå•†ï½œé—œä¿‚éˆåˆ†æï¼ˆå–®é æœå°‹ v10ï¼‰", page_icon="ğŸ—ï¸", layout="wide")
st.title("ğŸ—ï¸ ç™¾å¤§å»ºå•†ï½œé—œä¿‚éˆåˆ†æï¼ˆå–®é æœå°‹ v10ï¼‰")
try:
    p = Path(__file__)
    st.caption(
        f"ğŸ”– ç‰ˆæœ¬ï¼šv10 | æª”æ¡ˆï¼š{p.name} | ä¿®æ”¹æ™‚é–“ï¼š{datetime.fromtimestamp(p.stat().st_mtime):%Y-%m-%d %H:%M:%S}"
    )
except Exception:
    st.caption("ğŸ”– ç‰ˆæœ¬ï¼šv10")

st.markdown(
    """
    <style>
    .chip {display:inline-block; padding:4px 10px; border-radius:999px; background:#F1F5F9; border:1px solid #E2E8F0; font-size:12px; margin-right:8px;}
    .card {padding:16px 16px; border-radius:16px; border:1px solid #E2E8F0; background:#FFFFFF; box-shadow:0 1px 2px rgba(0,0,0,0.04); margin-bottom:12px;}
    .stTabs [data-baseweb="tab-list"] { gap: 6px; }
    .stTabs [data-baseweb="tab"] { border: 1px solid #e5e7eb; padding: 6px 12px; border-radius: 10px; background: #fafafa; }
    .stTabs [aria-selected="true"] { background: #eef2ff !important; border-color:#c7d2fe !important; }
    </style>
    """,
    unsafe_allow_html=True,
)

# ====================== Helpers ======================
@st.cache_data
def read_any(file):
    if file.name.lower().endswith(".csv"):
        return pd.read_csv(file)
    else:
        return pd.read_excel(file, engine="openpyxl")

def clean_name(x):
    s = "" if pd.isna(x) else str(x)
    s = s.replace("\u3000", " ").strip()
    s = re.sub(r"\s+", " ", s)
    if s == "" or s.lower() in {"nan", "none"} or s == "0":
        return np.nan
    return s

def coerce_num(s):
    if s is None or (isinstance(s, float) and math.isnan(s)):
        return np.nan
    if isinstance(s, (int, float, np.number)):
        return float(s)
    s = str(s).replace(",", "").replace("%", "").strip()
    if s in ("", "nan", "None"):
        return np.nan
    try:
        return float(s)
    except Exception:
        return np.nan

def normalize_ratio(series):
    s = series.apply(coerce_num)
    if s.max(skipna=True) is not None and s.max(skipna=True) > 1.000001:
        return s / 100.0
    return s

def pct_str(x):
    """è¼¸å…¥ 0~1 æˆ– 0~100ï¼Œè¼¸å‡º 'xx.xx%'ï¼ˆå››æ¨äº”å…¥å…©ä½ï¼‰"""
    if pd.isna(x):
        return "-"
    v = float(x)
    if v <= 1.0:
        v = v * 100.0
    d = Decimal(str(v)).quantize(Decimal("0.00"), rounding=ROUND_HALF_UP)
    return f"{d}%"

def get_col_by_pos_or_name(df, pos, name_candidates):
    cols = df.columns.tolist()
    try:
        col_by_pos = df.columns[pos]
    except Exception:
        col_by_pos = None
    if col_by_pos is not None:
        return col_by_pos
    for n in name_candidates:
        if n in cols:
            return n
    return None

# å¹³å‡é…æ¯”ï¼ˆæŒ‰æ°´é›»ç­‰æ¬Šï¼‰
def avg_dealer_ratio_across_unique_mep(rel_subset: pd.DataFrame) -> pd.DataFrame:
    meps = [m for m in rel_subset["æ°´é›»å…¬å¸"].dropna().unique().tolist() if isinstance(m, str) and m != ""]
    n = len(meps)
    if n == 0:
        return pd.DataFrame(columns=["ç¶“éŠ·å•†","å¹³å‡é…æ¯”"])
    sums = defaultdict(float)
    for mep in meps:
        g = rel_subset[rel_subset["æ°´é›»å…¬å¸"] == mep]
        rmap = g.groupby("ç¶“éŠ·å•†")["é…æ¯”"].mean().to_dict()
        for d, r in rmap.items():
            if pd.isna(d):
                continue
            sums[str(d)] += float(r or 0.0)
    rows = [(dealer, s / n) for dealer, s in sums.items()]
    out = pd.DataFrame(rows, columns=["ç¶“éŠ·å•†","å¹³å‡é…æ¯”"]).sort_values("å¹³å‡é…æ¯”", ascending=False)
    return out

# ====================== ä¸Šå‚³ ======================
file = st.file_uploader(
    "ä¸Šå‚³ Excel æˆ– CSV æª”ï¼ˆå›ºå®šæ¬„ä½ï¼šD=å»ºè¨­ã€E=ç‡Ÿé€ ã€F=æ°´é›»ã€G=å¹´ç”¨é‡ã€H/J/L=ç¶“éŠ·ã€I/K/M=é…æ¯”ï¼‰",
    type=["xlsx", "xls", "csv"],
    help="Excel éœ€ä½¿ç”¨ openpyxl è§£æ",
)
if not file:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
    st.stop()

df_raw = read_any(file)

# æ¬„ä½å®šä½ï¼ˆ0-basedï¼‰ï¼šD=3 E=4 F=5 G=6 H=7 I=8 J=9 K=10 L=11 M=12
col_dev = get_col_by_pos_or_name(df_raw, 3, ["å»ºå•†","å»ºè¨­å…¬å¸","å»ºè¨­å…¬å¸(æ¥­ä¸»)"])
col_con = get_col_by_pos_or_name(df_raw, 4, ["ç‡Ÿé€ å…¬å¸","ç‡Ÿé€ å•†"])
col_mep = get_col_by_pos_or_name(df_raw, 5, ["æ°´é›»å…¨å","æ°´é›»å…¬å¸","æ©Ÿé›»å…¬å¸","æ©Ÿé›»å» å•†"])
col_vol = get_col_by_pos_or_name(df_raw, 6, ["å¹´ä½¿ç”¨é‡/è¬","å¹´ä½¿ç”¨é‡(è¬)","ç”¨é‡_è¬"])
col_dA = get_col_by_pos_or_name(df_raw, 7, ["ç¶“éŠ·å•†A","ç¶“éŠ·A","ç¶“éŠ·å•†1"])
col_rA = get_col_by_pos_or_name(df_raw, 8, ["ç¶“éŠ·Aä½”æ¯”(%)","ç¶“éŠ·å•†Aé…æ¯”","Aé…æ¯”"])
col_dB = get_col_by_pos_or_name(df_raw, 9, ["ç¶“éŠ·å•†B","ç¶“éŠ·B","ç¶“éŠ·å•†2"])
col_rB = get_col_by_pos_or_name(df_raw, 10, ["ç¶“éŠ·Bä½”æ¯”(%)","ç¶“éŠ·å•†Bé…æ¯”","Bé…æ¯”"])
col_dC = get_col_by_pos_or_name(df_raw, 11, ["ç¶“éŠ·å•†C","ç¶“éŠ·ï¼£","ç¶“éŠ·å•†3"])
col_rC = get_col_by_pos_or_name(df_raw, 12, ["ç¶“éŠ·ï¼£ä½”æ¯”(%)","ç¶“éŠ·Cä½”æ¯”(%)","ç¶“éŠ·å•†Cé…æ¯”","Cé…æ¯”"])

required = [col_dev, col_con, col_mep]
if any(c is None for c in required):
    st.error("æ‰¾ä¸åˆ°å¿…è¦æ¬„ä½ï¼ˆä¾æ¬„ä½ä½ç½® D/E/F å–å¾—å¤±æ•—ï¼‰ã€‚è«‹ç¢ºèªè³‡æ–™æ¬„åºã€‚")
    st.stop()

# ====================== è½‰æ›ï¼ˆä¸ä»¥GåŠ æ¬Šï¼›% å…©ä½å°æ•¸ï¼‰ ======================
df = df_raw.rename(columns={
    col_dev:"å»ºè¨­å…¬å¸", col_con:"ç‡Ÿé€ å…¬å¸", col_mep:"æ°´é›»å…¬å¸",
    (col_vol or "G"): "å¹´ä½¿ç”¨é‡_è¬",
    col_dA:"ç¶“éŠ·å•†A", col_rA:"ç¶“éŠ·Aæ¯”",
    col_dB:"ç¶“éŠ·å•†B", col_rB:"ç¶“éŠ·Bæ¯”",
    col_dC:"ç¶“éŠ·å•†C", col_rC:"ç¶“éŠ·Cæ¯”",
}).copy()

for c in ["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","ç¶“éŠ·å•†A","ç¶“éŠ·å•†B","ç¶“éŠ·å•†C"]:
    if c in df.columns:
        df[c] = df[c].apply(clean_name)

if "å¹´ä½¿ç”¨é‡_è¬" in df.columns:
    df["å¹´ä½¿ç”¨é‡_è¬"] = df["å¹´ä½¿ç”¨é‡_è¬"].apply(coerce_num)

for c in ["ç¶“éŠ·Aæ¯”","ç¶“éŠ·Bæ¯”","ç¶“éŠ·Cæ¯”"]:
    if c in df.columns:
        df[c] = normalize_ratio(df[c])

# ç¶“éŠ·å±•é–‹ï¼ˆç”¨é…æ¯”ï¼Œä¸ä¹˜ä»¥Gï¼‰
dealer_blocks = []
if "ç¶“éŠ·å•†A" in df.columns and "ç¶“éŠ·Aæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","ç¶“éŠ·å•†A","ç¶“éŠ·Aæ¯”"]]
                         .rename(columns={"ç¶“éŠ·å•†A":"ç¶“éŠ·å•†","ç¶“éŠ·Aæ¯”":"é…æ¯”"}))
if "ç¶“éŠ·å•†B" in df.columns and "ç¶“éŠ·Bæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","ç¶“éŠ·å•†B","ç¶“éŠ·Bæ¯”"]]
                         .rename(columns={"ç¶“éŠ·å•†B":"ç¶“éŠ·å•†","ç¶“éŠ·Bæ¯”":"é…æ¯”"}))
if "ç¶“éŠ·å•†C" in df.columns and "ç¶“éŠ·Cæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","ç¶“éŠ·å•†C","ç¶“éŠ·Cæ¯”"]]
                         .rename(columns={"ç¶“éŠ·å•†C":"ç¶“éŠ·å•†","ç¶“éŠ·Cæ¯”":"é…æ¯”"}))
rel = (pd.concat(dealer_blocks, ignore_index=True)
       if dealer_blocks else pd.DataFrame(columns=["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","ç¶“éŠ·å•†","é…æ¯”"]))
rel["ç¶“éŠ·å•†"] = rel["ç¶“éŠ·å•†"].apply(clean_name)
rel = rel.dropna(subset=["ç¶“éŠ·å•†","æ°´é›»å…¬å¸"]).copy()

# æ°´é›»å¹´ç”¨é‡ï¼ˆæ¯å®¶æ°´é›»ä¸€å€‹å€¼ï¼›è‹¥é‡è¤‡å–é¦–å€‹éç©ºï¼‰
mep_vol_map = df.groupby("æ°´é›»å…¬å¸")["å¹´ä½¿ç”¨é‡_è¬"].apply(
    lambda s: s.dropna().iloc[0] if s.dropna().size>0 else np.nan
).to_dict()

# ====================== è§’è‰²é¸æ“‡ ======================
role = st.radio("è§’è‰²", ["å»ºè¨­å…¬å¸", "ç‡Ÿé€ å…¬å¸", "æ°´é›»å…¬å¸", "ç¶“éŠ·å•†"], horizontal=True)
chart_type = st.radio("åœ–è¡¨", ["åœ“é¤…åœ–", "é•·æ¢åœ–"], index=0, horizontal=True)

def options_for(role):
    if role == "å»ºè¨­å…¬å¸":
        return sorted(df["å»ºè¨­å…¬å¸"].dropna().unique().tolist())
    if role == "ç‡Ÿé€ å…¬å¸":
        return sorted(df["ç‡Ÿé€ å…¬å¸"].dropna().unique().tolist())
    if role == "æ°´é›»å…¬å¸":
        return sorted(df["æ°´é›»å…¬å¸"].dropna().unique().tolist())
    if role == "ç¶“éŠ·å•†":
        return sorted(rel["ç¶“éŠ·å•†"].dropna().unique().tolist())
    return []

all_opts = options_for(role)
kw = st.text_input("æœå°‹å…¬å¸ï¼ˆæ¨¡ç³Šï¼‰", "")
filtered_opts = [o for o in all_opts if isinstance(o, str) and (kw.lower() in o.lower() if kw else True)]
target = st.selectbox("é¸æ“‡å…¬å¸", filtered_opts)
if not target:
    st.stop()

st.markdown(f'<span class="chip">{role}</span><span class="chip">{target}</span>', unsafe_allow_html=True)

# ====================== å…±ç”¨å°å·¥å…· ======================
def share_table(df_in, group_cols, name_col):
    cnt = df_in.groupby(group_cols).size().reset_index(name="æ¬¡æ•¸")
    tot = cnt["æ¬¡æ•¸"].sum()
    if tot == 0:
        return pd.DataFrame(columns=[name_col,"æ¬¡æ•¸","å æ¯”"])
    cnt["å æ¯”"] = cnt["æ¬¡æ•¸"] / tot
    cnt["å æ¯”"] = cnt["å æ¯”"].apply(pct_str)
    return cnt.sort_values("æ¬¡æ•¸", ascending=False)

def draw_chart(df_plot, name_col, value_col, title):
    if df_plot is None or df_plot.empty:
        st.info("æ²’æœ‰è³‡æ–™å¯è¦–è¦ºåŒ–ã€‚")
        return
    pastel = px.colors.qualitative.Pastel
    if chart_type == "é•·æ¢åœ–":
        fig = px.bar(df_plot, x=name_col, y=value_col, title=title,
                     color=name_col, color_discrete_sequence=pastel, template="simple_white")
        fig.update_layout(showlegend=False)
    else:
        fig = px.pie(df_plot, names=name_col, values=value_col, title=title,
                     color=name_col, color_discrete_sequence=pastel, template="simple_white")
    st.plotly_chart(fig, use_container_width=True)

# ====================== è³‡æ–™åˆ‡ç‰‡ ======================
down_dealer_raw = None   # è¦–è¦ºç”¨æ•¸å€¼ï¼ˆå»ºè¨­/ç‡Ÿé€ ï¼šå¹³å‡é…æ¯”ï¼›æ°´é›»ï¼šé¡åº¦_è¬ï¼‰
down_dealer_tbl = None   # è¡¨æ ¼ç”¨ï¼ˆï¼…å­—ä¸²æˆ–å«é¡åº¦ï¼‰
down_mep = None          # æ°´é›»å…¬å¸åˆ—è¡¨ï¼ˆå«æ¬¡æ•¸/å æ¯”ï¼›ç¶“éŠ·å•†è¦–åœ–æœƒåŠ é…æ¯”ï¼‰
up_tbl = None            # ä¸Šæ¸¸æˆ–åˆä½œç‡Ÿé€ åˆ—è¡¨

if role == "å»ºè¨­å…¬å¸":
    df_sel = df[df["å»ºè¨­å…¬å¸"] == target]
    up_tbl = share_table(df_sel, ["ç‡Ÿé€ å…¬å¸"], "ç‡Ÿé€ å…¬å¸")      # for æ¦‚è¦½ï¼šç‡Ÿé€ å…¬å¸
    down_mep = share_table(df_sel, ["æ°´é›»å…¬å¸"], "æ°´é›»å…¬å¸")     # for æ¦‚è¦½ï¼šæ°´é›»å…¬å¸
    rel_sel = rel[rel["å»ºè¨­å…¬å¸"] == target]
    down_dealer_raw = avg_dealer_ratio_across_unique_mep(rel_sel)
    down_dealer_tbl = down_dealer_raw.copy()
    if not down_dealer_tbl.empty:
        down_dealer_tbl["å¹³å‡é…æ¯”"] = down_dealer_tbl["å¹³å‡é…æ¯”"].apply(pct_str)

elif role == "ç‡Ÿé€ å…¬å¸":
    df_sel = df[df["ç‡Ÿé€ å…¬å¸"] == target]
    up_tbl = share_table(df_sel, ["å»ºè¨­å…¬å¸"], "å»ºè¨­å…¬å¸")
    down_mep = share_table(df_sel, ["æ°´é›»å…¬å¸"], "æ°´é›»å…¬å¸")
    rel_sel = rel[rel["ç‡Ÿé€ å…¬å¸"] == target]
    down_dealer_raw = avg_dealer_ratio_across_unique_mep(rel_sel)
    down_dealer_tbl = down_dealer_raw.copy()
    if not down_dealer_tbl.empty:
        down_dealer_tbl["å¹³å‡é…æ¯”"] = down_dealer_tbl["å¹³å‡é…æ¯”"].apply(pct_str)

elif role == "æ°´é›»å…¬å¸":
    df_sel = df[df["æ°´é›»å…¬å¸"] == target]
    # ç¶“éŠ·å•†åœ¨è©²æ°´é›»çš„é…æ¯” + é¡åº¦(è¬)ï¼ˆé…æ¯”Ã—å¹´ç”¨é‡ï¼‰
    rel_sel = rel[rel["æ°´é›»å…¬å¸"] == target]
    mep_vol = df_sel["å¹´ä½¿ç”¨é‡_è¬"].dropna().unique()
    vol_val = float(mep_vol[0]) if len(mep_vol) > 0 and not pd.isna(mep_vol[0]) else 0.0

    dealer_ratio = (rel_sel.groupby("ç¶“éŠ·å•†")["é…æ¯”"].mean()
                    .reset_index().sort_values("é…æ¯”", ascending=False))
    dealer_ratio["é¡åº¦_è¬"] = dealer_ratio["é…æ¯”"].astype(float) * vol_val
    down_dealer_raw = dealer_ratio.rename(columns={"é…æ¯”":"é…æ¯”"})  # è¦–è¦ºç”¨ï¼šæˆ‘å€‘æœƒç”¨ é¡åº¦_è¬
    down_dealer_tbl = down_dealer_raw.copy()
    if not down_dealer_tbl.empty:
        down_dealer_tbl["é…æ¯”"] = down_dealer_tbl["é…æ¯”"].apply(pct_str)
        down_dealer_tbl["é¡åº¦_è¬"] = down_dealer_tbl["é¡åº¦_è¬"].round(2)

    # ä¸Šæ¸¸ï¼šå»ºè¨­Ã—ç‡Ÿé€ ï¼ˆé¡¯ç¤ºåœ¨æ¦‚è¦½ï¼‰
    up_tbl = share_table(
        df_sel.assign(_å…¬å¸=df_sel["å»ºè¨­å…¬å¸"].fillna("")+" Ã— "+df_sel["ç‡Ÿé€ å…¬å¸"].fillna("")),
        ["_å…¬å¸"], "å…¬å¸"
    )
    down_mep = None  # æ°´é›»è¦–åœ–ä¸éœ€è¦åˆ—å‡ºå…¶ä»–æ°´é›»

elif role == "ç¶“éŠ·å•†":
    # ç¶“éŠ·å•†è¦–åœ–ï¼šåˆä½œæ°´é›»ï¼ˆä¸¦åŠ ä¸Šæ­¤ç¶“éŠ·åœ¨å„æ°´é›»çš„å¹³å‡é…æ¯”ï¼‰
    df_sel = rel[rel["ç¶“éŠ·å•†"] == target].merge(
        df, on=["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], how="left", suffixes=("","_df")
    )
    down_mep = share_table(df_sel, ["æ°´é›»å…¬å¸"], "æ°´é›»å…¬å¸")
    r_df = (rel[rel["ç¶“éŠ·å•†"] == target]
            .groupby("æ°´é›»å…¬å¸")["é…æ¯”"].mean().reset_index()
            .rename(columns={"é…æ¯”":"è©²ç¶“éŠ·å•†é…æ¯”"}))
    if not r_df.empty:
        r_df["è©²ç¶“éŠ·å•†é…æ¯”"] = r_df["è©²ç¶“éŠ·å•†é…æ¯”"].apply(pct_str)
        down_mep = down_mep.merge(r_df, on="æ°´é›»å…¬å¸", how="left")
    up_tbl = None

# ====================== KPIï¼ˆæ©«æ’ï¼‰ ======================
with st.container():
    st.markdown('<div class="card">', unsafe_allow_html=True)
    c1, c2, c3, c4, c5 = st.columns(5)
    cnt_rows = len(df_sel) if isinstance(df_sel, pd.DataFrame) else 0
    n_dev = df_sel["å»ºè¨­å…¬å¸"].nunique() if "å»ºè¨­å…¬å¸" in df_sel.columns else 0
    n_con = df_sel["ç‡Ÿé€ å…¬å¸"].nunique() if "ç‡Ÿé€ å…¬å¸" in df_sel.columns else 0
    n_mep = df_sel["æ°´é›»å…¬å¸"].nunique() if "æ°´é›»å…¬å¸" in df_sel.columns else 0
    if role in ["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"]:
        n_dealer = (rel[rel[role]==target]["ç¶“éŠ·å•†"].nunique()
                    if role in ["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸"]
                    else (rel[rel["æ°´é›»å…¬å¸"]==target]["ç¶“éŠ·å•†"].nunique()))
    else:
        n_dealer = df_sel["ç¶“éŠ·å•†"].nunique() if "ç¶“éŠ·å•†" in df_sel.columns else 0
    c1.metric("è³‡æ–™ç­†æ•¸", f"{cnt_rows:,}")
    c2.metric("å»ºè¨­å®¶æ•¸", f"{n_dev:,}")
    c3.metric("ç‡Ÿé€ å®¶æ•¸", f"{n_con:,}")
    c4.metric("æ°´é›»å®¶æ•¸", f"{n_mep:,}")
    c5.metric("ç¶“éŠ·å®¶æ•¸", f"{n_dealer:,}")
    st.markdown('</div>', unsafe_allow_html=True)

# ====================== Tabsï¼šæ¦‚è¦½ / åˆä½œå°è±¡ / ç«¶çˆ­è€… / åŒ¯å‡º ======================
tab_overview, tab_partners, tab_comp, tab_export = st.tabs(["æ¦‚è¦½", "åˆä½œå°è±¡", "ç«¶çˆ­è€…", "åŒ¯å‡º"])

with tab_overview:
    # ä¾è§’è‰²çš„å¿«é€Ÿç¸½æ”¬
    if role == "å»ºè¨­å…¬å¸":
        st.markdown("#### ğŸ¤ åˆä½œå°è±¡")
        # é¡¯ç¤ºæ™‚æŠŠã€Œæ¬¡æ•¸ã€æ”¹åã€Œåˆä½œæ¬¡æ•¸ã€
        if up_tbl is not None and not up_tbl.empty:
            st.write("ãƒ»ç‡Ÿé€ å…¬å¸")
            st.dataframe(up_tbl.rename(columns={"æ¬¡æ•¸":"åˆä½œæ¬¡æ•¸"}), use_container_width=True)
        if down_mep is not None and not down_mep.empty:
            st.write("ãƒ»æ°´é›»å…¬å¸")
            st.dataframe(down_mep.rename(columns={"æ¬¡æ•¸":"åˆä½œæ¬¡æ•¸"}), use_container_width=True)
        if down_dealer_tbl is not None and not down_dealer_tbl.empty:
            st.write("ãƒ»çµ‚ç«¯ç¶“éŠ·å•†")
            st.dataframe(down_dealer_tbl, use_container_width=True)

    elif role == "ç¶“éŠ·å•†":
        st.markdown("#### ğŸ¤ åˆä½œæ°´é›»")
        st.dataframe(down_mep if down_mep is not None and not down_mep.empty else pd.DataFrame(),
                     use_container_width=True)

    elif role == "æ°´é›»å…¬å¸":
        st.markdown("#### ğŸ¤ åˆä½œå°è±¡")
        # ç¶“éŠ·å•†ï¼ˆé…æ¯”ï¼‹é¡åº¦ï¼‰ï¼‹ å¹´ç”¨é‡å‚™è¨»
        if down_dealer_tbl is not None and not down_dealer_tbl.empty:
            st.write("ãƒ»ç¶“éŠ·å•†ï¼ˆé…æ¯”èˆ‡é¡åº¦ï¼‰")
            st.dataframe(down_dealer_tbl.rename(columns={"é¡åº¦_è¬":"é¡åº¦(è¬)"}),
                         use_container_width=True)
        mep_vol = df_sel["å¹´ä½¿ç”¨é‡_è¬"].dropna().unique()
        memo = f"{mep_vol[0]} è¬" if len(mep_vol)>0 else "â€”"
        st.info(f"ğŸ“Œ é ä¼°å¹´ä½¿ç”¨é‡ï¼š{memo}ï¼ˆå·²ç”¨æ–¼åœ–è¡¨çš„é‡‘é¡æ›ç®—ï¼‰")

    else:  # ç‡Ÿé€ å…¬å¸ç¶­æŒåŸæœ¬å‘ˆç¾
        st.markdown("#### ğŸ“Œ å¿«é€Ÿç¸½æ”¬")
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**ä¸Šæ¸¸**")
            st.dataframe(up_tbl if up_tbl is not None and not up_tbl.empty else pd.DataFrame(),
                         use_container_width=True)
        with c2:
            st.markdown("**ç›´æ¥åˆä½œå°è±¡**")
            st.write("ãƒ»æ°´é›»å…¬å¸")
            st.dataframe(down_mep if down_mep is not None and not down_mep.empty else pd.DataFrame(),
                         use_container_width=True)
            st.write("ãƒ»çµ‚ç«¯ç¶“éŠ·å•†ï¼ˆå¹³å‡é…æ¯”ï½œæŒ‰æ°´é›»ç­‰æ¬Šï¼‰")
            st.dataframe(down_dealer_tbl if down_dealer_tbl is not None and not down_dealer_tbl.empty else pd.DataFrame(),
                         use_container_width=True)

with tab_partners:
    st.markdown("#### ğŸ“ˆ è¦–è¦ºåŒ–")
    # å»ºè¨­/ç‡Ÿé€ ï¼šæ°´é›»å‡ºç¾æ¬¡æ•¸ï¼›å»ºè¨­/ç‡Ÿé€ ï¼šç¶“éŠ·å•†å¹³å‡é…æ¯”ï¼›æ°´é›»ï¼šç¶“éŠ·å•†é‡‘é¡ï¼›ç¶“éŠ·å•†ï¼šæ°´é›»å‡ºç¾æ¬¡æ•¸
    if role in ["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸"] and down_mep is not None and not down_mep.empty:
        draw_chart(down_mep, down_mep.columns[0], "æ¬¡æ•¸", f"{role} â†’ æ°´é›»å…¬å¸ åˆä½œæ¬¡æ•¸")
    if role == "æ°´é›»å…¬å¸" and down_dealer_raw is not None and not down_dealer_raw.empty:
        # æ”¹ç”¨é‡‘é¡
        draw_chart(down_dealer_raw.rename(columns={"é¡åº¦_è¬":"é‡‘é¡(è¬)"}), "ç¶“éŠ·å•†", "é‡‘é¡(è¬)", "æ°´é›»å…¬å¸ â†’ çµ‚ç«¯ç¶“éŠ·å•† é‡‘é¡(è¬)")
    if role == "ç‡Ÿé€ å…¬å¸" and down_dealer_raw is not None and not down_dealer_raw.empty:
        draw_chart(down_dealer_raw, "ç¶“éŠ·å•†", "å¹³å‡é…æ¯”", "ç‡Ÿé€ å…¬å¸ â†’ çµ‚ç«¯ç¶“éŠ·å•† å¹³å‡é…æ¯”ï¼ˆæŒ‰æ°´é›»ç­‰æ¬Šï¼‰")
    if role == "å»ºè¨­å…¬å¸" and down_dealer_raw is not None and not down_dealer_raw.empty:
        draw_chart(down_dealer_raw, "ç¶“éŠ·å•†", "å¹³å‡é…æ¯”", "å»ºè¨­å…¬å¸ â†’ çµ‚ç«¯ç¶“éŠ·å•† å¹³å‡é…æ¯”ï¼ˆæŒ‰æ°´é›»ç­‰æ¬Šï¼‰")
    if role == "ç¶“éŠ·å•†" and down_mep is not None and not down_mep.empty:
        draw_chart(down_mep, "æ°´é›»å…¬å¸", "æ¬¡æ•¸", "ç¶“éŠ·å•† â†’ æ°´é›»å…¬å¸ åˆä½œæ¬¡æ•¸")

with tab_comp:
    st.markdown("#### âš”ï¸ ç«¶çˆ­è€…")
    # å»ºè¨­å…¬å¸ï¼šä¸æä¾›ç«¶çˆ­è€…åˆ†æ
    if role == "å»ºè¨­å…¬å¸":
        st.info("æ­¤è§’è‰²ä¸æä¾›ç«¶çˆ­è€…åˆ†æã€‚")
    else:
        # === ç«¶çˆ­è€…å‡½å¼ ===
        def competitor_table_water(df_base, target_mep):
            g = df_base[df_base["æ°´é›»å…¬å¸"].notna()]
            cons = g[g["æ°´é›»å…¬å¸"] == target_mep]["ç‡Ÿé€ å…¬å¸"].dropna().unique().tolist()
            if not cons:
                return pd.DataFrame(columns=["ç«¶çˆ­å°æ‰‹","å…±åŒå‡ºç¾æ¬¡æ•¸"])
            cand = g[g["ç‡Ÿé€ å…¬å¸"].isin(cons)]
            co = cand[cand["æ°´é›»å…¬å¸"] != target_mep].groupby("æ°´é›»å…¬å¸").size().reset_index(name="å…±åŒå‡ºç¾æ¬¡æ•¸")
            return co.sort_values("å…±åŒå‡ºç¾æ¬¡æ•¸", ascending=False)

        def competitor_table_dealer(rel_base, target_dealer):
            target_clients = rel_base[rel_base["ç¶“éŠ·å•†"] == target_dealer]["æ°´é›»å…¬å¸"].dropna().unique().tolist()
            target_client_set = set(target_clients)
            target_total_clients = len(target_client_set)
            tgt_ratio_map = (rel_base[rel_base["ç¶“éŠ·å•†"] == target_dealer]
                             .groupby("æ°´é›»å…¬å¸")["é…æ¯”"].mean().to_dict())
            target_total_market = 0.0
            for mep in target_client_set:
                vol = float(mep_vol_map.get(mep, 0.0) or 0.0)
                r_t = float(tgt_ratio_map.get(mep, 0.0) or 0.0)
                target_total_market += vol * r_t
            stats = {}
            for mep, grp in rel_base.groupby("æ°´é›»å…¬å¸"):
                if mep not in target_client_set:
                    continue
                vol = float(mep_vol_map.get(mep, 0.0) or 0.0)
                ratios = grp.groupby("ç¶“éŠ·å•†")["é…æ¯”"].mean().to_dict()
                if target_dealer not in ratios:
                    continue
                r_t = float(ratios[target_dealer] or 0.0)
                for dealer, r_c in ratios.items():
                    if dealer == target_dealer or pd.isna(dealer):
                        continue
                    d = stats.setdefault(dealer, {"å…±åŒå®¢æˆ¶æ•¸":0,"overlap_ratio_sum":0.0,"å…±åŒå¸‚å ´é¡åº¦":0.0,"é‡ç–Šå¸‚å ´é¡åº¦":0.0})
                    d["å…±åŒå®¢æˆ¶æ•¸"] += 1
                    r_min = min(float(r_c or 0.0), r_t)
                    d["overlap_ratio_sum"] += r_min
                    d["å…±åŒå¸‚å ´é¡åº¦"] += vol
                    d["é‡ç–Šå¸‚å ´é¡åº¦"] += vol * r_min
            rows = []
            for dealer, d in stats.items():
                shared = d["å…±åŒå®¢æˆ¶æ•¸"]
                if shared <= 0:
                    continue
                comp_index = d["overlap_ratio_sum"] / shared
                shared_pct = (shared / target_total_clients) if target_total_clients > 0 else 0.0
                overlap_market_share = (d["é‡ç–Šå¸‚å ´é¡åº¦"] / target_total_market) if target_total_market > 0 else 0.0
                threat = "é«˜" if overlap_market_share > 0.30 else ("ä¸­" if overlap_market_share >= 0.15 else "ä½")
                rows.append({
                    "ç«¶çˆ­å°æ‰‹": dealer,
                    "å…±åŒå®¢æˆ¶æ•¸": shared,
                    "å…±åŒå®¢æˆ¶æ•¸å æ¯”": pct_str(shared_pct),
                    "ç«¶çˆ­æŒ‡æ•¸": pct_str(comp_index),
                    "å…±åŒå¸‚å ´é¡åº¦(è¬)": round(d["å…±åŒå¸‚å ´é¡åº¦"], 2),
                    "é‡ç–Šå¸‚å ´é¡åº¦(è¬)": round(d["é‡ç–Šå¸‚å ´é¡åº¦"], 2),
                    "é‡ç–Šå¸‚å ´å æ¯”": pct_str(overlap_market_share),
                    "å¨è„…ç¨‹åº¦": threat,
                })
            out = pd.DataFrame(rows)
            if out.empty:
                return out
            cat = pd.Categorical(out["å¨è„…ç¨‹åº¦"], categories=["é«˜","ä¸­","ä½"], ordered=True)
            out = out.assign(_order=cat).sort_values(["_order","é‡ç–Šå¸‚å ´å æ¯”","å…±åŒå®¢æˆ¶æ•¸"], ascending=[True, False, False]).drop(columns="_order")
            return out

        def union_overlap_share(rel_base, target_dealer):
            """å»é‡å¾Œçš„æ•´é«”è¢«ç«¶çˆ­è¦†è“‹ç‡ï¼ˆâ‰¤100%ï¼‰"""
            target_clients = rel_base[rel_base["ç¶“éŠ·å•†"] == target_dealer]["æ°´é›»å…¬å¸"].dropna().unique().tolist()
            tgt_ratio_map = (rel_base[rel_base["ç¶“éŠ·å•†"] == target_dealer]
                             .groupby("æ°´é›»å…¬å¸")["é…æ¯”"].mean().to_dict())
            total_target = 0.0
            union_overlap = 0.0
            for mep in target_clients:
                vol = float(mep_vol_map.get(mep, 0.0) or 0.0)
                r_t = float(tgt_ratio_map.get(mep, 0.0) or 0.0)
                comp_sum = float((rel_base[rel_base["æ°´é›»å…¬å¸"]==mep]
                                  .groupby("ç¶“éŠ·å•†")["é…æ¯”"].mean()
                                  .drop(labels=[target_dealer], errors="ignore")
                                  .sum()) or 0.0)
                union_overlap += vol * min(r_t, comp_sum)
                total_target  += vol * r_t
            return (union_overlap / total_target) if total_target > 0 else 0.0

        # === é¡¯ç¤º ===
        if role == "æ°´é›»å…¬å¸":
            st.dataframe(competitor_table_water(df, target), use_container_width=True)
        elif role == "ç¶“éŠ·å•†":
            comp_tbl = competitor_table_dealer(rel, target)
            st.dataframe(comp_tbl, use_container_width=True)
            # å»é‡å¾Œçš„æ•´é«”è¦†è“‹ç‡
            union_share = union_overlap_share(rel, target)
            st.caption(f"ğŸ“Œ å»é‡å¾Œçš„ã€æ•´é«”è¢«ç«¶çˆ­è¦†è“‹ç‡ã€ï¼š{pct_str(union_share)}")
            st.info("è¨»ï¼šè¡¨æ ¼ä¸­çš„ã€é‡ç–Šå¸‚å ´å æ¯”ã€ç‚ºèˆ‡å–®ä¸€å°æ‰‹çš„é…å°å¼é‡ç–Šï¼Œå°æ‰‹å¤šå®¶ç›¸åŠ å¯èƒ½ > 100%ï¼›ä¸Šè¿°å»é‡æŒ‡æ¨™å‰‡ä¸æœƒè¶…é 100%ã€‚")
        elif role == "ç‡Ÿé€ å…¬å¸":
            devs = df[df["ç‡Ÿé€ å…¬å¸"] == target]["å»ºè¨­å…¬å¸"].dropna().unique().tolist()
            cand = df[df["å»ºè¨­å…¬å¸"].isin(devs)]
            co = (cand[cand["ç‡Ÿé€ å…¬å¸"] != target].groupby("ç‡Ÿé€ å…¬å¸")
                  .size().reset_index(name="å…±åŒå‡ºç¾æ¬¡æ•¸").sort_values("å…±åŒå‡ºç¾æ¬¡æ•¸", ascending=False))
            st.dataframe(co, use_container_width=True)

with tab_export:
    st.markdown("#### â¬‡ï¸ åŒ¯å‡ºé—œä¿‚æ˜ç´°ï¼ˆç¶“éŠ·é…æ¯”å±•é–‹ï¼Œä¸å«å¹´ç”¨é‡åŠ æ¬Šï¼‰")
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df_raw.to_excel(writer, index=False, sheet_name="åŸå§‹è³‡æ–™")
        df.to_excel(writer, index=False, sheet_name="ä¸»æª”(å›ºå®šæ¬„ä½å‘½å)")
        rel.to_excel(writer, index=False, sheet_name="é—œä¿‚æ˜ç´°(é…æ¯”)")
    st.download_button(
        "ä¸‹è¼‰ Excel",
        data=output.getvalue(),
        file_name="relations_search_dashboard_v10.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# æ¸…é™¤å¿«å–
with st.expander("ğŸ§¹ æ¸…é™¤å¿«å–"):
    if st.button("æ¸…é™¤ @st.cache_data ä¸¦é‡è¼‰"):
        st.cache_data.clear()
        st.rerun()
