
import io
import math
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="ç™¾å¤§å»ºå•†ï½œé—œä¿‚éˆåˆ†æå„€è¡¨æ¿", page_icon="ğŸ—ï¸", layout="wide")
st.title("ğŸ—ï¸ ç™¾å¤§å»ºå•†é—œä¿‚éˆåˆ†æå„€è¡¨æ¿")
st.caption("ä¸Šå‚³ Excel/CSV -> æ¬„ä½å°æ‡‰/æ¸…ç† -> é—œä¿‚æ‹†è§£èˆ‡é…æ¯” -> å„€è¡¨æ¿ï¼ˆç¸½è¦½/è²¢ç»/ç«¶çˆ­/é—œä¿‚åœ–ï¼‰-> åŒ¯å‡º")

# =====================================================
# 0) Helpers
# =====================================================
@st.cache_data
def read_any(file):
    if file.name.lower().endswith(".csv"):
        return pd.read_csv(file)
    else:
        return pd.read_excel(file, engine="openpyxl")

def _coerce_num(s):
    \"\"\"Coerce to float, handling commas/percents/strings.\"\"\"
    if s is None:
        return np.nan
    if isinstance(s, (int, float, np.number)):
        return s
    s = str(s).replace(",", "").replace("%", "").strip()
    if s in ("", "nan", "None"):
        return np.nan
    try:
        return float(s)
    except Exception:
        return np.nan

def normalize_ratio(series):
    \"\"\"Normalize ratio to 0~1; if it looks like 0~100, divide by 100.\"\"\"
    s = series.apply(_coerce_num)
    if s.max(skipna=True) is not None and s.max(skipna=True) > 1.000001:
        return s / 100.0
    return s

def fmt_num(x, digits=2):
    if pd.isna(x):
        return "-"
    return f"{x:,.{digits}f}"

# =====================================================
# 1) Upload
# =====================================================
file = st.file_uploader(
    "ä¸Šå‚³ Excel æˆ– CSV æª”",
    type=["xlsx", "xls", "csv"],
    help="æœ€å¤š 200 MBï¼›Excel éœ€ä½¿ç”¨ openpyxl è§£æ",
)

sample_cols = [
    "å»ºå•†", "ç‡Ÿé€ å…¬å¸", "æ°´é›»å…¨å", "å¹´ä½¿ç”¨é‡/è¬",
    "ç¶“éŠ·å•†A", "ç¶“éŠ·Aä½”æ¯”(%)",
    "ç¶“éŠ·å•†B", "ç¶“éŠ·Bä½”æ¯”(%)",
    "ç¶“éŠ·å•†C", "ç¶“éŠ·ï¼£ä½”æ¯”(%)",
]
with st.expander("æœŸæœ›æ¬„ä½çµæ§‹ï¼ˆå°ç…§ä½ çš„è³‡æ–™ï¼‰", expanded=False):
    st.write(pd.DataFrame({
        "æ¬„ä½": sample_cols,
        "èªªæ˜": ["å»ºè¨­å…¬å¸", "ç‡Ÿé€ å…¬å¸", "æ°´é›»å…¬å¸å…¨å", "è©²æ°´é›»ä¼°è¨ˆå¹´ç”¨é‡(è¬å…ƒ)",
               "é…åˆç¶“éŠ·å•†1", "ç¶“éŠ·å•†1é…æ¯”", "é…åˆç¶“éŠ·å•†2", "ç¶“éŠ·å•†2é…æ¯”", "é…åˆç¶“éŠ·å•†3", "ç¶“éŠ·å•†3é…æ¯”"]
    }))

if not file:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
    st.stop()

df_raw = read_any(file)
st.subheader("åŸå§‹è³‡æ–™é è¦½")
st.dataframe(df_raw.head(20), use_container_width=True)

# =====================================================
# 2) Column mapping
# =====================================================
st.sidebar.header("âš™ï¸ æ“ä½œå€")
st.sidebar.subheader("æ¬„ä½å°æ‡‰")
def select_map(title, default_candidates):
    options = ["ï¼ˆæœªå°æ‡‰ï¼‰"] + df_raw.columns.tolist()
    default = next((c for c in default_candidates if c in df_raw.columns), "ï¼ˆæœªå°æ‡‰ï¼‰")
    return st.sidebar.selectbox(title, options, index=options.index(default) if default in options else 0)

col_dev = select_map("å»ºè¨­å…¬å¸æ¬„ä½", ["å»ºå•†", "å»ºè¨­å…¬å¸", "å»ºè¨­å…¬å¸(æ¥­ä¸»)"])
col_con = select_map("ç‡Ÿé€ å…¬å¸æ¬„ä½", ["ç‡Ÿé€ å…¬å¸", "ç‡Ÿé€ å•†"])
col_mep = select_map("æ°´é›»å…¬å¸æ¬„ä½", ["æ°´é›»å…¨å", "æ°´é›»å…¬å¸", "æ©Ÿé›»å…¬å¸", "æ©Ÿé›»å» å•†"])
col_vol = select_map("å¹´ä½¿ç”¨é‡(è¬å…ƒ)æ¬„ä½", ["å¹´ä½¿ç”¨é‡/è¬", "å¹´ä½¿ç”¨é‡(è¬)", "ç”¨é‡_è¬"])

col_dA = select_map("ç¶“éŠ·å•†Aæ¬„ä½", ["ç¶“éŠ·å•†A", "ç¶“éŠ·A", "ç¶“éŠ·å•†1"])
col_rA = select_map("ç¶“éŠ·Aé…æ¯”æ¬„ä½", ["ç¶“éŠ·Aä½”æ¯”(%)", "ç¶“éŠ·å•†Aé…æ¯”", "Aé…æ¯”"])
col_dB = select_map("ç¶“éŠ·å•†Bæ¬„ä½", ["ç¶“éŠ·å•†B", "ç¶“éŠ·B", "ç¶“éŠ·å•†2"])
col_rB = select_map("ç¶“éŠ·Bé…æ¯”æ¬„ä½", ["ç¶“éŠ·Bä½”æ¯”(%)", "ç¶“éŠ·å•†Bé…æ¯”", "Bé…æ¯”"])
col_dC = select_map("ç¶“éŠ·å•†Cæ¬„ä½", ["ç¶“éŠ·å•†C", "ç¶“éŠ·ï¼£", "ç¶“éŠ·å•†3"])
col_rC = select_map("ç¶“éŠ·Cé…æ¯”æ¬„ä½", ["ç¶“éŠ·ï¼£ä½”æ¯”(%)", "ç¶“éŠ·Cä½”æ¯”(%)", "ç¶“éŠ·å•†Cé…æ¯”", "Cé…æ¯”"])

required = [col_dev, col_con, col_mep, col_vol]
if any(c == "ï¼ˆæœªå°æ‡‰ï¼‰" for c in required):
    st.error("è«‹è‡³å°‘å°æ‡‰ã€å»ºè¨­å…¬å¸ / ç‡Ÿé€ å…¬å¸ / æ°´é›»å…¬å¸ / å¹´ä½¿ç”¨é‡(è¬å…ƒ)ã€å››å€‹æ¬„ä½ã€‚")
    st.stop()

# =====================================================
# 3) Cleaning & explode dealers
# =====================================================
df = df_raw.rename(columns={
    col_dev: "å»ºè¨­å…¬å¸", col_con: "ç‡Ÿé€ å…¬å¸", col_mep: "æ°´é›»å…¬å¸", col_vol: "å¹´ä½¿ç”¨é‡_è¬",
    col_dA: "ç¶“éŠ·å•†A", col_rA: "ç¶“éŠ·Aæ¯”",
    col_dB: "ç¶“éŠ·å•†B", col_rB: "ç¶“éŠ·Bæ¯”",
    col_dC: "ç¶“éŠ·å•†C", col_rC: "ç¶“éŠ·Cæ¯”",
}).copy()

for c in ["å¹´ä½¿ç”¨é‡_è¬"]:
    df[c] = df[c].apply(_coerce_num)

for c in ["ç¶“éŠ·Aæ¯”", "ç¶“éŠ·Bæ¯”", "ç¶“éŠ·Cæ¯”"]:
    if c in df.columns:
        df[c] = normalize_ratio(df[c])

dealer_blocks = []
if "ç¶“éŠ·å•†A" in df.columns and "ç¶“éŠ·Aæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†A","ç¶“éŠ·Aæ¯”"]]\
                         .rename(columns={"ç¶“éŠ·å•†A":"ç¶“éŠ·å•†","ç¶“éŠ·Aæ¯”":"é…æ¯”"}))
if "ç¶“éŠ·å•†B" in df.columns and "ç¶“éŠ·Bæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†B","ç¶“éŠ·Bæ¯”"]]\
                         .rename(columns={"ç¶“éŠ·å•†B":"ç¶“éŠ·å•†","ç¶“éŠ·Bæ¯”":"é…æ¯”"}))
if "ç¶“éŠ·å•†C" in df.columns and "ç¶“éŠ·Cæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†C","ç¶“éŠ·Cæ¯”"]]\
                         .rename(columns={"ç¶“éŠ·å•†C":"ç¶“éŠ·å•†","ç¶“éŠ·Cæ¯”":"é…æ¯”"}))

rel = pd.concat(dealer_blocks, ignore_index=True) if dealer_blocks else pd.DataFrame(columns=["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†","é…æ¯”"])
rel["ç¶“éŠ·å•†"] = rel["ç¶“éŠ·å•†"].replace({0: np.nan, "0": np.nan, "": np.nan}).astype("string")
rel = rel.dropna(subset=["ç¶“éŠ·å•†"]).copy()

rel["æ‰¿æ¥é‡_è¬"] = rel["å¹´ä½¿ç”¨é‡_è¬"] * rel["é…æ¯”"]
rel["æ‰¿æ¥é‡_å…ƒ"] = rel["æ‰¿æ¥é‡_è¬"] * 10000

# ratio check
ratio_check = rel.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], dropna=False)["é…æ¯”"].sum().reset_index()
ratio_check["é…æ¯”åˆè¨ˆ"] = ratio_check["é…æ¯”"]
ratio_check["æ˜¯å¦=1(Â±0.01)"] = np.isclose(ratio_check["é…æ¯”åˆè¨ˆ"], 1.0, atol=0.01)

with st.expander("é…æ¯”æª¢æŸ¥ï¼ˆåŒä¸€æ°´é›»å…¬å¸çš„ç¶“éŠ·å•†é…æ¯”åŠ ç¸½æ‡‰ â‰ˆ 1ï¼‰", expanded=False):
    st.dataframe(ratio_check.sort_values("æ˜¯å¦=1(Â±0.01)"), use_container_width=True)

auto_norm = st.sidebar.checkbox("è‡ªå‹•æ­£è¦åŒ–æ¯å€‹æ°´é›»å…¬å¸çš„é…æ¯”ï¼ˆä½¿åˆè¨ˆ=1ï¼‰", value=True)
if auto_norm and not rel.empty:
    sums = rel.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"])["é…æ¯”"].transform(lambda s: s.sum() if s.sum() else 1.0)
    rel["é…æ¯”"] = rel["é…æ¯”"] / sums
    rel["æ‰¿æ¥é‡_è¬"] = rel["å¹´ä½¿ç”¨é‡_è¬"] * rel["é…æ¯”"]
    rel["æ‰¿æ¥é‡_å…ƒ"] = rel["æ‰¿æ¥é‡_è¬"] * 10000

# =====================================================
# 4) Filters
# =====================================================
st.sidebar.subheader("ç¯©é¸æ¢ä»¶")
dev_sel = st.sidebar.multiselect("å»ºè¨­å…¬å¸", sorted(rel["å»ºè¨­å…¬å¸"].dropna().unique().tolist()))
con_sel = st.sidebar.multiselect("ç‡Ÿé€ å…¬å¸", sorted(rel["ç‡Ÿé€ å…¬å¸"].dropna().unique().tolist()))
mep_sel = st.sidebar.multiselect("æ°´é›»å…¬å¸", sorted(rel["æ°´é›»å…¬å¸"].dropna().unique().tolist()))
dea_sel = st.sidebar.multiselect("ç¶“éŠ·å•†", sorted(rel["ç¶“éŠ·å•†"].dropna().unique().tolist()))

filtered = rel.copy()
if dev_sel: filtered = filtered[filtered["å»ºè¨­å…¬å¸"].isin(dev_sel)]
if con_sel: filtered = filtered[filtered["ç‡Ÿé€ å…¬å¸"].isin(con_sel)]
if mep_sel: filtered = filtered[filtered["æ°´é›»å…¬å¸"].isin(mep_sel)]
if dea_sel: filtered = filtered[filtered["ç¶“éŠ·å•†"].isin(dea_sel)]

st.subheader("é—œä¿‚æ˜ç´°ï¼ˆéæ¿¾å¾Œï¼‰")
st.dataframe(filtered, use_container_width=True)

# KPI
tot_mep = filtered["æ°´é›»å…¬å¸"].nunique()
tot_dea = filtered["ç¶“éŠ·å•†"].nunique()
sum_vol = filtered["æ‰¿æ¥é‡_è¬"].sum()

c1, c2, c3 = st.columns(3)
c1.metric("æ°´é›»å…¬å¸æ•¸é‡", f"{tot_mep}")
c2.metric("ç¶“éŠ·å•†æ•¸é‡", f"{tot_dea}")
c3.metric("ç¶“éŠ·å•†æ‰¿æ¥ç¸½é‡(è¬å…ƒ)", fmt_num(sum_vol, 0))

# =====================================================
# 5) Charts
# =====================================================
st.subheader("åœ–è¡¨è¦–è¦ºåŒ–")

with st.expander("TOP ç¶“éŠ·å•†æ‰¿æ¥é‡", expanded=True):
    topN = st.slider("é¡¯ç¤ºå‰ N å", 5, 30, 10, 1)
    dea_rank = (filtered.groupby("ç¶“éŠ·å•†", dropna=False)["æ‰¿æ¥é‡_è¬"]
                .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False).head(topN))
    fig = px.bar(dea_rank, x="ç¶“éŠ·å•†", y="æ‰¿æ¥é‡_è¬", title="ç¶“éŠ·å•†æ‰¿æ¥é‡(è¬å…ƒ)")
    st.plotly_chart(fig, use_container_width=True)

with st.expander("TOP æ°´é›»å…¬å¸å¹´ä½¿ç”¨é‡ï¼ˆæŒ‰é…æ¯”æ‹†åˆ†åŠ ç¸½ï¼‰", expanded=False):
    mep_rank = (filtered.groupby("æ°´é›»å…¬å¸", dropna=False)["æ‰¿æ¥é‡_è¬"]
                .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False).head(15))
    fig = px.bar(mep_rank, x="æ°´é›»å…¬å¸", y="æ‰¿æ¥é‡_è¬", title="æ°´é›»å…¬å¸åŠ æ¬Šå¾Œä½¿ç”¨é‡(è¬å…ƒ)")
    st.plotly_chart(fig, use_container_width=True)

with st.expander("å»ºè¨­å…¬å¸ / ç‡Ÿé€ å…¬å¸ è²¢ç»åº¦", expanded=False):
    t1, t2 = st.tabs(["å»ºè¨­å…¬å¸è²¢ç»", "ç‡Ÿé€ å…¬å¸è²¢ç»"])
    with t1:
        dev_rank = (filtered.groupby("å»ºè¨­å…¬å¸", dropna=False)["æ‰¿æ¥é‡_è¬"]
                    .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False))
        fig = px.bar(dev_rank, x="å»ºè¨­å…¬å¸", y="æ‰¿æ¥é‡_è¬", title="å»ºè¨­å…¬å¸å¸¶ä¾†çš„åŠ æ¬Šä½¿ç”¨é‡(è¬å…ƒ)")
        st.plotly_chart(fig, use_container_width=True)
    with t2:
        con_rank = (filtered.groupby("ç‡Ÿé€ å…¬å¸", dropna=False)["æ‰¿æ¥é‡_è¬"]
                    .sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False))
        fig = px.bar(con_rank, x="ç‡Ÿé€ å…¬å¸", y="æ‰¿æ¥é‡_è¬", title="ç‡Ÿé€ å…¬å¸å¸¶ä¾†çš„åŠ æ¬Šä½¿ç”¨é‡(è¬å…ƒ)")
        st.plotly_chart(fig, use_container_width=True)

with st.expander("ç¶“éŠ·å•†ç«¶åˆï¼šåŒä¸€æ°´é›»å…¬å¸çš„å¤šå®¶ç¶“éŠ·é…æ¯”", expanded=False):
    comp = (filtered.groupby(["æ°´é›»å…¬å¸", "ç¶“éŠ·å•†"], dropna=False)["é…æ¯”"]
            .sum().reset_index())
    pivot = comp.pivot(index="æ°´é›»å…¬å¸", columns="ç¶“éŠ·å•†", values="é…æ¯”").fillna(0.0)
    st.dataframe(pivot, use_container_width=True)
    st.caption("æ•¸å€¼ç‚ºé…æ¯”(0~1)ï¼Œå¯è§€å¯ŸåŒä¸€æ°´é›»å…¬å¸å¦‚ä½•åœ¨å¤šå®¶ç¶“éŠ·å•†é–“åˆ†é…ã€‚")

with st.expander("é—œä¿‚æµå‘åœ–ï¼ˆSankeyï¼‰", expanded=False):
    devs = filtered["å»ºè¨­å…¬å¸"].dropna().unique().tolist()
    cons = filtered["ç‡Ÿé€ å…¬å¸"].dropna().unique().tolist()
    meps = filtered["æ°´é›»å…¬å¸"].dropna().unique().tolist()
    deas = filtered["ç¶“éŠ·å•†"].dropna().unique().tolist()

    nodes = (
        [f"å»ºè¨­ï½œ{d}" for d in devs] +
        [f"ç‡Ÿé€ ï½œ{c}" for c in cons] +
        [f"æ°´é›»ï½œ{m}" for m in meps] +
        [f"ç¶“éŠ·ï½œ{d}" for d in deas]
    )
    node_index = {name: i for i, name in enumerate(nodes)}

    # å»ºè¨­->ç‡Ÿé€ 
    s1, t1, v1 = [], [], []
    link1 = (filtered.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index())
    for _, r in link1.iterrows():
        s1.append(node_index[f"å»ºè¨­ï½œ{r['å»ºè¨­å…¬å¸']}"])
        t1.append(node_index[f"ç‡Ÿé€ ï½œ{r['ç‡Ÿé€ å…¬å¸']}"])
        v1.append(max(r["æ‰¿æ¥é‡_è¬"], 0))

    # ç‡Ÿé€ ->æ°´é›»
    s2, t2, v2 = [], [], []
    link2 = (filtered.groupby(["ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index())
    for _, r in link2.iterrows():
        s2.append(node_index[f"ç‡Ÿé€ ï½œ{r['ç‡Ÿé€ å…¬å¸']}"])
        t2.append(node_index[f"æ°´é›»ï½œ{r['æ°´é›»å…¬å¸']}"])
        v2.append(max(r["æ‰¿æ¥é‡_è¬"], 0))

    # æ°´é›»->ç¶“éŠ·
    s3, t3, v3 = [], [], []
    link3 = (filtered.groupby(["æ°´é›»å…¬å¸","ç¶“éŠ·å•†"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index())
    for _, r in link3.iterrows():
        s3.append(node_index[f"æ°´é›»ï½œ{r['æ°´é›»å…¬å¸']}"])
        t3.append(node_index[f"ç¶“éŠ·ï½œ{r['ç¶“éŠ·å•†']}"])
        v3.append(max(r["æ‰¿æ¥é‡_è¬"], 0))

    source = s1 + s2 + s3
    target = t1 + t2 + t3
    value  = v1 + v2 + v3

    if len(source) == 0:
        st.info("ç›®å‰ç¯©é¸çµæœæ²’æœ‰å¯è¦–çš„é—œä¿‚æµã€‚")
    else:
        fig = go.Figure(data=[go.Sankey(
            node=dict(pad=12, thickness=20, line=dict(width=0.5), label=nodes),
            link=dict(source=source, target=target, value=value)
        )])
        fig.update_layout(title_text="å»ºè¨­â†’ç‡Ÿé€ â†’æ°´é›»â†’ç¶“éŠ· é—œä¿‚æµï¼ˆæ‰¿æ¥é‡_è¬ï¼‰", font_size=12)
        st.plotly_chart(fig, use_container_width=True)

# =====================================================
# 6) Export
# =====================================================
st.subheader("ä¸‹è¼‰çµæœ")
csv_bytes = filtered.to_csv(index=False).encode("utf-8-sig")
st.download_button("ä¸‹è¼‰ é—œä¿‚æ˜ç´° CSV", data=csv_bytes, file_name="relations_detail.csv", mime="text/csv")

output = io.BytesIO()
with pd.ExcelWriter(output, engine="openpyxl") as writer:
    df_raw.to_excel(writer, index=False, sheet_name="åŸå§‹è³‡æ–™")
    rel.to_excel(writer, index=False, sheet_name="é—œä¿‚æ˜ç´°_æœªç¯©é¸")
    filtered.to_excel(writer, index=False, sheet_name="é—œä¿‚æ˜ç´°_å·²ç¯©é¸")
    ratio_check.to_excel(writer, index=False, sheet_name="é…æ¯”æª¢æŸ¥")
st.download_button(
    "ä¸‹è¼‰ Excelï¼ˆå¤šå·¥ä½œè¡¨ï¼‰",
    data=output.getvalue(),
    file_name="relations_dashboard_export.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

