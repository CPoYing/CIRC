
import io
import re
import math
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="ç™¾å¤§å»ºå•†ï½œå®Œæ•´é—œä¿‚éˆåˆ†æå„€è¡¨æ¿", page_icon="ğŸ—ï¸", layout="wide")
st.title("ğŸ—ï¸ ç™¾å¤§å»ºå•†ï½œå®Œæ•´é—œä¿‚éˆåˆ†æå„€è¡¨æ¿ï¼ˆå›ºå®šæ¬„ä½ï¼Œç„¡æ“ä½œå€ï¼‰")
st.caption("D=å»ºè¨­ã€E=ç‡Ÿé€ ã€F=æ°´é›»ã€G=å¹´ä½¿ç”¨é‡(è¬å…ƒ)ã€H/J/L=ç¶“éŠ·å•†ã€I/K/M=é…æ¯” â†’ è‡ªå‹•æ‹†è§£ï¼Œè¼¸å‡ºå¤šé¢å‘åˆ†æ")

# ====================== Helpers ======================
@st.cache_data
def read_any(file):
    if file.name.lower().endswith(".csv"):
        return pd.read_csv(file)
    else:
        return pd.read_excel(file, engine="openpyxl")

def clean_name(x):
    s = "" if pd.isna(x) else str(x)
    s = s.replace("\\u3000", " ").strip()
    s = re.sub(r"\\s+", " ", s)
    if s == "" or s.lower() in {"nan", "none"} or s == "0":
        return np.nan
    return s

def coerce_num(s):
    if s is None or (isinstance(s, float) and math.isnan(s)):
        return np.nan
    if isinstance(s, (int, float, np.number)):
        return float(s)
    s = str(s).replace(",", "").replace("%", "").strip()
    if s in ("", "nan", "None"):
        return np.nan
    try:
        return float(s)
    except Exception:
        return np.nan

def normalize_ratio(series):
    s = series.apply(coerce_num)
    if s.max(skipna=True) is not None and s.max(skipna=True) > 1.000001:
        return s / 100.0
    return s

def fmt_num(x, digits=2):
    if pd.isna(x):
        return "-"
    return f"{x:,.{digits}f}"

def get_col_by_pos_or_name(df, pos, name_candidates):
    cols = df.columns.tolist()
    try:
        col_by_pos = df.columns[pos]
    except Exception:
        col_by_pos = None
    if col_by_pos is not None:
        return col_by_pos
    for n in name_candidates:
        if n in cols:
            return n
    return None

# ====================== Upload ======================
file = st.file_uploader(
    "ä¸Šå‚³ Excel æˆ– CSV æª”ï¼ˆå›ºå®šæ¬„ä½ç‰ˆï¼›ä¸éœ€è¦ä»»ä½•æ“ä½œï¼‰",
    type=["xlsx", "xls", "csv"],
    help="æœ€å¤š 200 MBï¼›Excel éœ€ä½¿ç”¨ openpyxl è§£æ",
)

if not file:
    st.info("è«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
    st.stop()

df_raw = read_any(file)

# å›ºå®šæ¬„ä½ä½ç½®ï¼ˆ0-basedï¼‰ï¼šD=3, E=4, F=5, G=6, H=7, I=8, J=9, K=10, L=11, M=12
col_dev = get_col_by_pos_or_name(df_raw, 3, ["å»ºå•†","å»ºè¨­å…¬å¸","å»ºè¨­å…¬å¸(æ¥­ä¸»)"])
col_con = get_col_by_pos_or_name(df_raw, 4, ["ç‡Ÿé€ å…¬å¸","ç‡Ÿé€ å•†"])
col_mep = get_col_by_pos_or_name(df_raw, 5, ["æ°´é›»å…¨å","æ°´é›»å…¬å¸","æ©Ÿé›»å…¬å¸","æ©Ÿé›»å» å•†"])
col_vol = get_col_by_pos_or_name(df_raw, 6, ["å¹´ä½¿ç”¨é‡/è¬","å¹´ä½¿ç”¨é‡(è¬)","ç”¨é‡_è¬"])

col_dA = get_col_by_pos_or_name(df_raw, 7, ["ç¶“éŠ·å•†A","ç¶“éŠ·A","ç¶“éŠ·å•†1"])
col_rA = get_col_by_pos_or_name(df_raw, 8, ["ç¶“éŠ·Aä½”æ¯”(%)","ç¶“éŠ·å•†Aé…æ¯”","Aé…æ¯”"])
col_dB = get_col_by_pos_or_name(df_raw, 9, ["ç¶“éŠ·å•†B","ç¶“éŠ·B","ç¶“éŠ·å•†2"])
col_rB = get_col_by_pos_or_name(df_raw, 10, ["ç¶“éŠ·Bä½”æ¯”(%)","ç¶“éŠ·å•†Bé…æ¯”","Bé…æ¯”"])
col_dC = get_col_by_pos_or_name(df_raw, 11, ["ç¶“éŠ·å•†C","ç¶“éŠ·ï¼£","ç¶“éŠ·å•†3"])
col_rC = get_col_by_pos_or_name(df_raw, 12, ["ç¶“éŠ·ï¼£ä½”æ¯”(%)","ç¶“éŠ·Cä½”æ¯”(%)","ç¶“éŠ·å•†Cé…æ¯”","Cé…æ¯”"])

required = [col_dev, col_con, col_mep, col_vol]
if any(c is None for c in required):
    st.error("æ‰¾ä¸åˆ°å¿…è¦æ¬„ä½ï¼ˆä¾æ¬„ä½ä½ç½® D/E/F/G å–å¾—å¤±æ•—ï¼‰ã€‚è«‹ç¢ºèªè³‡æ–™çš„æ¬„åºæ˜¯å¦æ­£ç¢ºã€‚")
    st.stop()

with st.expander("ğŸ” æ¬„ä½å°æ‡‰ï¼ˆå›ºå®šç‰ˆï¼›åƒ…ä¾›æŸ¥çœ‹ï¼‰", expanded=True):
    st.write(pd.DataFrame({
        "è§’è‰²":["å»ºè¨­å…¬å¸(D)","ç‡Ÿé€ å…¬å¸(E)","æ°´é›»å…¬å¸(F)","å¹´ä½¿ç”¨é‡(è¬)(G)","ç¶“éŠ·å•†(H)","é…æ¯”(I)","ç¶“éŠ·å•†(J)","é…æ¯”(K)","ç¶“éŠ·å•†(L)","é…æ¯”(M)"],
        "æ¬„ä½":[col_dev,col_con,col_mep,col_vol,col_dA,col_rA,col_dB,col_rB,col_dC,col_rC]
    }))

# ====================== Transform ======================
df = df_raw.rename(columns={
    col_dev:"å»ºè¨­å…¬å¸", col_con:"ç‡Ÿé€ å…¬å¸", col_mep:"æ°´é›»å…¬å¸", col_vol:"å¹´ä½¿ç”¨é‡_è¬",
    col_dA:"ç¶“éŠ·å•†A", col_rA:"ç¶“éŠ·Aæ¯”",
    col_dB:"ç¶“éŠ·å•†B", col_rB:"ç¶“éŠ·Bæ¯”",
    col_dC:"ç¶“éŠ·å•†C", col_rC:"ç¶“éŠ·Cæ¯”",
}).copy()

# æ¸…ç†åç¨±
for c in ["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","ç¶“éŠ·å•†A","ç¶“éŠ·å•†B","ç¶“éŠ·å•†C"]:
    if c in df.columns:
        df[c] = df[c].apply(clean_name)

df["å¹´ä½¿ç”¨é‡_è¬"] = df["å¹´ä½¿ç”¨é‡_è¬"].apply(coerce_num)
for c in ["ç¶“éŠ·Aæ¯”","ç¶“éŠ·Bæ¯”","ç¶“éŠ·Cæ¯”"]:
    if c in df.columns:
        df[c] = normalize_ratio(df[c])

# ç¶“éŠ·å•†å±•é–‹
dealer_blocks = []
if "ç¶“éŠ·å•†A" in df.columns and "ç¶“éŠ·Aæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†A","ç¶“éŠ·Aæ¯”"]].rename(columns={"ç¶“éŠ·å•†A":"ç¶“éŠ·å•†","ç¶“éŠ·Aæ¯”":"é…æ¯”"}))
if "ç¶“éŠ·å•†B" in df.columns and "ç¶“éŠ·Bæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†B","ç¶“éŠ·Bæ¯”"]].rename(columns={"ç¶“éŠ·å•†B":"ç¶“éŠ·å•†","ç¶“éŠ·Bæ¯”":"é…æ¯”"}))
if "ç¶“éŠ·å•†C" in df.columns and "ç¶“éŠ·Cæ¯”" in df.columns:
    dealer_blocks.append(df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†C","ç¶“éŠ·Cæ¯”"]].rename(columns={"ç¶“éŠ·å•†C":"ç¶“éŠ·å•†","ç¶“éŠ·Cæ¯”":"é…æ¯”"}))

rel = pd.concat(dealer_blocks, ignore_index=True) if dealer_blocks else pd.DataFrame(columns=["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸","å¹´ä½¿ç”¨é‡_è¬","ç¶“éŠ·å•†","é…æ¯”"])
rel["ç¶“éŠ·å•†"] = rel["ç¶“éŠ·å•†"].replace({0: np.nan, "0": np.nan, "": np.nan}).astype("string")
rel = rel.dropna(subset=["ç¶“éŠ·å•†"]).copy()
# æ¸…ç†ç¶“éŠ·å•†åç¨±
rel["ç¶“éŠ·å•†"] = rel["ç¶“éŠ·å•†"].apply(clean_name)

# è¨ˆç®—æ‰¿æ¥é‡
rel["æ‰¿æ¥é‡_è¬"] = rel["å¹´ä½¿ç”¨é‡_è¬"] * rel["é…æ¯”"]
rel["æ‰¿æ¥é‡_å…ƒ"] = rel["æ‰¿æ¥é‡_è¬"] * 10000

# ====================== åŸºç¤çµ±è¨ˆ/é—œä¿‚æ•¸ ======================
count_dev = df["å»ºè¨­å…¬å¸"].nunique()
count_con = df["ç‡Ÿé€ å…¬å¸"].nunique()
count_mep = df["æ°´é›»å…¬å¸"].nunique()
count_dea = rel["ç¶“éŠ·å•†"].nunique()

pairs_dev_con = df[["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸"]].dropna().drop_duplicates().shape[0]
pairs_con_mep = df[["ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"]].dropna().drop_duplicates().shape[0]
pairs_mep_dea = rel[["æ°´é›»å…¬å¸","ç¶“éŠ·å•†"]].dropna().drop_duplicates().shape[0]

# é…æ¯”æª¢æŸ¥èˆ‡ä¾è³´åº¦
ratio_check = rel.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], dropna=False)["é…æ¯”"].sum().reset_index()
ratio_check["é…æ¯”åˆè¨ˆ"] = ratio_check["é…æ¯”"]
ratio_check["æ˜¯å¦=1(Â±0.01)"] = np.isclose(ratio_check["é…æ¯”åˆè¨ˆ"], 1.0, atol=0.01)

single_dep = (rel.groupby(["æ°´é›»å…¬å¸","ç¶“éŠ·å•†"], dropna=False)["é…æ¯”"].sum().reset_index())
top_ratio = single_dep.sort_values(["æ°´é›»å…¬å¸","é…æ¯”"], ascending=[True, False]).groupby("æ°´é›»å…¬å¸").head(1)
top_ratio["å–®ä¸€ä¾è³´>80%"] = top_ratio["é…æ¯”"] >= 0.8

# å»ºè¨­/ç‡Ÿé€  -> ç¶“éŠ·å•†çš„åŠ æ¬Šæ‰¿æ¥é‡ï¼ˆç”¨æ–¼é ç±¤ 1ï¼‰
dev_dealer = rel.groupby(["å»ºè¨­å…¬å¸","ç¶“éŠ·å•†"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index()
con_dealer = rel.groupby(["ç‡Ÿé€ å…¬å¸","ç¶“éŠ·å•†"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index()

def topk_table(df_pair, key_col, k=3):
    rows = []
    for key, g in df_pair.groupby(key_col):
        g = g.sort_values("æ‰¿æ¥é‡_è¬", ascending=False)
        top = g.head(k).reset_index(drop=True)
        row = {key_col: key}
        for i in range(k):
            if i < len(top):
                row[f"Top{i+1}ç¶“éŠ·å•†"] = top.loc[i, "ç¶“éŠ·å•†"]
                row[f"Top{i+1}ä»½é¡(è¬)"] = round(float(top.loc[i, "æ‰¿æ¥é‡_è¬"]), 2)
            else:
                row[f"Top{i+1}ç¶“éŠ·å•†"] = ""
                row[f"Top{i+1}ä»½é¡(è¬)"] = ""
        rows.append(row)
    return pd.DataFrame(rows).sort_values(f"Top1ä»½é¡(è¬)", ascending=False)

dev_top = topk_table(dev_dealer, "å»ºè¨­å…¬å¸", k=3)
con_top = topk_table(con_dealer, "ç‡Ÿé€ å…¬å¸", k=3)

# å»ºè¨­/ç‡Ÿé€  -> æ°´é›»åˆ†å¸ƒ
dev_mep = df.groupby(["å»ºè¨­å…¬å¸","æ°´é›»å…¬å¸"], dropna=False)["å¹´ä½¿ç”¨é‡_è¬"].sum().reset_index()
con_mep = df.groupby(["ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], dropna=False)["å¹´ä½¿ç”¨é‡_è¬"].sum().reset_index()

# æ°´é›»ä¹‹é–“ç«¶çˆ­ï¼ˆåŒä¸€ç‡Ÿé€ å…¬å¸åº•ä¸‹çš„å…±ç¾ï¼›ä»¥å¹´ä½¿ç”¨é‡_è¬ç‚ºæ¬Šé‡ï¼‰
def cooccurrence_pairs(df_group_key, item_col, weight_col):
    weights = {}
    matrix_index = set()
    for key, g in df.groupby(df_group_key):
        items = g[[item_col, weight_col]].dropna(subset=[item_col]).copy()
        items[item_col] = items[item_col].apply(clean_name)
        items = items.dropna(subset=[item_col])
        uniq = items[item_col].dropna().unique().tolist()
        uniq = [u for u in uniq if isinstance(u, str) and u != ""]
        if len(uniq) < 2:
            continue
        # ç¾¤çµ„æ¬Šé‡ï¼šä½¿ç”¨è©²ç¾¤çµ„çš„å¹´ä½¿ç”¨é‡ç¸½å’Œ
        group_w = float(items[weight_col].sum(skipna=True) or 0.0)
        for i in range(len(uniq)):
            for j in range(i+1, len(uniq)):
                a, b = sorted([uniq[i], uniq[j]])
                matrix_index.add(a); matrix_index.add(b)
                weights[(a,b)] = weights.get((a,b), 0.0) + group_w
    labels = sorted(matrix_index)
    mat = pd.DataFrame(0.0, index=labels, columns=labels)
    for (a,b), w in weights.items():
        mat.loc[a,b] = mat.loc[a,b] + w
        mat.loc[b,a] = mat.loc[b,a] + w
    return mat

mep_competition = cooccurrence_pairs(["ç‡Ÿé€ å…¬å¸"], "æ°´é›»å…¬å¸", "å¹´ä½¿ç”¨é‡_è¬")

# ç¶“éŠ·å•†ä¹‹é–“ç«¶åˆï¼ˆåŒä¸€æ°´é›»å…¬å¸ï¼›å¼·åº¦=å¹´ä½¿ç”¨é‡_è¬ * min(é…æ¯”i, é…æ¯”j)ï¼‰
def dealer_competition_matrix(rel_df):
    weights = {}
    labels = set()
    for mep, g in rel_df.groupby("æ°´é›»å…¬å¸"):
        g = g.dropna(subset=["ç¶“éŠ·å•†","é…æ¯”","å¹´ä½¿ç”¨é‡_è¬"]).copy()
        if g.empty:
            continue
        g["ç¶“éŠ·å•†"] = g["ç¶“éŠ·å•†"].apply(clean_name)
        mep_vol = float(g["å¹´ä½¿ç”¨é‡_è¬"].iloc[0] if "å¹´ä½¿ç”¨é‡_è¬" in g.columns else 0.0)
        dealers = g[["ç¶“éŠ·å•†","é…æ¯”"]].dropna().values.tolist()
        if len(dealers) < 2:
            continue
        for i in range(len(dealers)):
            for j in range(i+1, len(dealers)):
                a, ai = dealers[i]
                b, bi = dealers[j]
                if not isinstance(a, str) or not isinstance(b, str):
                    continue
                labels.add(a); labels.add(b)
                w = float(min(ai, bi) * mep_vol)
                key = tuple(sorted([a,b]))
                weights[key] = weights.get(key, 0.0) + w
    labels = sorted(labels)
    mat = pd.DataFrame(0.0, index=labels, columns=labels)
    for (a,b), w in weights.items():
        mat.loc[a,b] = mat.loc[a,b] + w
        mat.loc[b,a] = mat.loc[b,a] + w
    return mat

dealer_comp = dealer_competition_matrix(rel)

# ====================== Tabs ======================
tab0, tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“„ åŸå§‹è³‡æ–™",
    "ğŸ§­ é—œä¿‚æ¦‚è¦½",
    "ğŸ¢ å»ºè¨­ â†’ ç¶“éŠ·å•†",
    "ğŸ—ï¸ å»ºè¨­ â†” ç‡Ÿé€  çµæ§‹",
    "ğŸ”§ å»ºè¨­/ç‡Ÿé€  â†’ æ°´é›»",
    "âš”ï¸ æ°´é›»ç«¶çˆ­",
    "ğŸ¤ ç¶“éŠ·ç«¶åˆ",
])

# -------- Tab 0: åŸå§‹è³‡æ–™ --------
with tab0:
    st.subheader("åŸå§‹è³‡æ–™é è¦½")
    st.dataframe(df_raw, use_container_width=True)

# -------- Tab 1: é—œä¿‚æ¦‚è¦½ --------
with tab1:
    st.subheader("ç¸½è¦½ KPI èˆ‡é—œä¿‚æ•¸")
    c1, c2, c3, c4, c5, c6, c7 = st.columns(7)
    c1.metric("å»ºè¨­å…¬å¸æ•¸", f"{count_dev}")
    c2.metric("ç‡Ÿé€ å…¬å¸æ•¸", f"{count_con}")
    c3.metric("æ°´é›»å…¬å¸æ•¸", f"{count_mep}")
    c4.metric("ç¶“éŠ·å•†æ•¸", f"{count_dea}")
    c5.metric("å»ºè¨­â†’ç‡Ÿé€  é—œä¿‚æ•¸", f"{pairs_dev_con}")
    c6.metric("ç‡Ÿé€ â†’æ°´é›» é—œä¿‚æ•¸", f"{pairs_con_mep}")
    c7.metric("æ°´é›»â†’ç¶“éŠ· é—œä¿‚æ•¸", f"{pairs_mep_dea}")

    st.markdown("---")
    st.subheader("é—œä¿‚æ˜ç´°ï¼ˆç¶“éŠ·å•†é…æ¯”å±•é–‹ï¼‰")
    st.dataframe(rel, use_container_width=True)

    st.markdown("---")
    st.subheader("é—œä¿‚æµå‘åœ–ï¼ˆå»ºè¨­â†’ç‡Ÿé€ â†’æ°´é›»â†’ç¶“éŠ·ï¼‰")
    # æ§‹å»ºç¯€é»
    devs = [d for d in sorted(df["å»ºè¨­å…¬å¸"].dropna().unique().tolist()) if isinstance(d, str) and d != ""]
    cons = [c for c in sorted(df["ç‡Ÿé€ å…¬å¸"].dropna().unique().tolist()) if isinstance(c, str) and c != ""]
    meps = [m for m in sorted(df["æ°´é›»å…¬å¸"].dropna().unique().tolist()) if isinstance(m, str) and m != ""]
    deas = [d for d in sorted(rel["ç¶“éŠ·å•†"].dropna().unique().tolist()) if isinstance(d, str) and d != ""]

    nodes = (
        [f"å»ºè¨­ï½œ{d}" for d in devs] +
        [f"ç‡Ÿé€ ï½œ{c}" for c in cons] +
        [f"æ°´é›»ï½œ{m}" for m in meps] +
        [f"ç¶“éŠ·ï½œ{d}" for d in deas]
    )
    node_index = {name: i for i, name in enumerate(nodes)}

    def add_links(df_links, src_label, dst_label, value_col):
        s, t, v = [], [], []
        for _, r in df_links.iterrows():
            s_key = f"{src_label}ï½œ{r[src_label]}"
            t_key = f"{dst_label}ï½œ{r[dst_label]}"
            if s_key in node_index and t_key in node_index:
                s.append(node_index[s_key])
                t.append(node_index[t_key])
                v.append(max(float(r[value_col] or 0.0), 0.0))
        return s, t, v

    link1 = df.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸"], dropna=False)["å¹´ä½¿ç”¨é‡_è¬"].sum().reset_index()
    s1, t1_, v1 = add_links(link1, "å»ºè¨­å…¬å¸", "ç‡Ÿé€ å…¬å¸", "å¹´ä½¿ç”¨é‡_è¬")

    link2 = df.groupby(["ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], dropna=False)["å¹´ä½¿ç”¨é‡_è¬"].sum().reset_index()
    # rename for function compatibility
    link2 = link2.rename(columns={"ç‡Ÿé€ å…¬å¸":"ç‡Ÿé€ å…¬å¸", "æ°´é›»å…¬å¸":"æ°´é›»å…¬å¸"})
    s2, t2_, v2 = [], [], []
    for _, r in link2.iterrows():
        s_key = f"ç‡Ÿé€ ï½œ{r['ç‡Ÿé€ å…¬å¸']}"
        t_key = f"æ°´é›»ï½œ{r['æ°´é›»å…¬å¸']}"
        if s_key in node_index and t_key in node_index:
            s2.append(node_index[s_key]); t2_.append(node_index[t_key]); v2.append(max(float(r["å¹´ä½¿ç”¨é‡_è¬"] or 0.0), 0.0))

    link3 = rel.groupby(["æ°´é›»å…¬å¸","ç¶“éŠ·å•†"], dropna=False)["æ‰¿æ¥é‡_è¬"].sum().reset_index()
    s3, t3_, v3 = [], [], []
    for _, r in link3.iterrows():
        s_key = f"æ°´é›»ï½œ{r['æ°´é›»å…¬å¸']}"
        t_key = f"ç¶“éŠ·ï½œ{r['ç¶“éŠ·å•†']}"
        if s_key in node_index and t_key in node_index:
            s3.append(node_index[s_key]); t3_.append(node_index[t_key]); v3.append(max(float(r["æ‰¿æ¥é‡_è¬"] or 0.0), 0.0))

    source = s1 + s2 + s3
    target = t1_ + t2_ + t3_
    value  = v1 + v2 + v3

    if len(source) == 0:
        st.info("è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç”Ÿæˆé—œä¿‚æµã€‚")
    else:
        fig = go.Figure(data=[go.Sankey(
            node=dict(pad=12, thickness=20, line=dict(width=0.5), label=nodes),
            link=dict(source=source, target=target, value=value)
        )])
        fig.update_layout(title_text="å»ºè¨­â†’ç‡Ÿé€ â†’æ°´é›»â†’ç¶“éŠ· é—œä¿‚æµï¼ˆä»¥ç”¨é‡/æ‰¿æ¥é‡ç‚ºæ¬Šé‡ï¼‰", font_size=12)
        st.plotly_chart(fig, use_container_width=True)

# -------- Tab 2: å»ºè¨­ â†’ ç¶“éŠ·å•† --------
with tab2:
    st.subheader("å»ºè¨­å…¬å¸ â†’ æœ€å¯èƒ½ä¸‹å–®çš„ç¶“éŠ·å•†ï¼ˆåŠ æ¬Šæ‰¿æ¥é‡ Top3ï¼‰")
    st.dataframe(dev_top, use_container_width=True)

    st.markdown("---")
    st.subheader("ç¸½è¦½ï¼šå„å»ºè¨­å…¬å¸çš„ç¶“éŠ·å•†æ‰¿æ¥é‡")
    dev_tot = dev_dealer.groupby("å»ºè¨­å…¬å¸")["æ‰¿æ¥é‡_è¬"].sum().reset_index().sort_values("æ‰¿æ¥é‡_è¬", ascending=False)
    fig = px.bar(dev_tot.head(30), x="å»ºè¨­å…¬å¸", y="æ‰¿æ¥é‡_è¬", title="å»ºè¨­å…¬å¸å°ç¶“éŠ·å•†çš„åŠ æ¬Šæ‰¿æ¥é‡ï¼ˆç¸½å’Œï¼‰")
    st.plotly_chart(fig, use_container_width=True)

    st.caption("é‚è¼¯ï¼šå»ºè¨­â†’ç‡Ÿé€ â†’æ°´é›»â†’ç¶“éŠ·ï¼Œä½¿ç”¨ å¹´ä½¿ç”¨é‡_è¬ Ã— ç¶“éŠ·é…æ¯” åŠ ç¸½åˆ°ç¶“éŠ·å•†å±¤ã€‚")

# -------- Tab 3: å»ºè¨­ â†” ç‡Ÿé€  çµæ§‹ --------
with tab3:
    st.subheader("å»ºè¨­ â†” ç‡Ÿé€  é—œä¿‚ç†±åŠ›åœ–ï¼ˆå‡ºç¾æ¬¡æ•¸ï¼‰")
    pair_count = df.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸"]).size().reset_index(name="æ¬¡æ•¸")
    if not pair_count.empty:
        heat = pair_count.pivot(index="å»ºè¨­å…¬å¸", columns="ç‡Ÿé€ å…¬å¸", values="æ¬¡æ•¸").fillna(0.0)
        fig = px.imshow(heat, aspect="auto", title="å»ºè¨­Ã—ç‡Ÿé€  å‡ºç¾æ¬¡æ•¸ç†±åŠ›åœ–")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç¹ªè£½ç†±åŠ›åœ–ã€‚")

    st.markdown("---")
    st.subheader("ç‡Ÿé€ é›†ä¸­åº¦ï¼ˆåŒä¸€å»ºè¨­å…¬å¸çš„ç‡Ÿé€ å æ¯”ï¼‰")
    dev_con_share = df.groupby(["å»ºè¨­å…¬å¸","ç‡Ÿé€ å…¬å¸"]).size().groupby(level=0).apply(lambda s: s / s.sum()).reset_index(name="å æ¯”")
    # HHI æŒ‡æ¨™
    hhi = dev_con_share.groupby("å»ºè¨­å…¬å¸")["å æ¯”"].apply(lambda s: (s**2).sum()).reset_index(name="HHI")
    top_concentrated = hhi.sort_values("HHI", ascending=False)
    st.dataframe(top_concentrated, use_container_width=True)
    st.caption("HHI è¶Šé«˜è¡¨ç¤ºç‡Ÿé€ æ›´é›†ä¸­ï¼ˆå¯èƒ½ç‚ºå­å…¬å¸æˆ–ç‰¹å®šåˆä½œé—œä¿‚ï¼‰ã€‚")

# -------- Tab 4: å»ºè¨­/ç‡Ÿé€  â†’ æ°´é›» --------
with tab4:
    t1, t2 = st.tabs(["å»ºè¨­ â†’ æ°´é›» åˆ†å¸ƒ", "ç‡Ÿé€  â†’ æ°´é›» åˆ†å¸ƒ"])
    with t1:
        st.subheader("å»ºè¨­å…¬å¸ä¸‹çš„æ°´é›»ä½¿ç”¨é‡åˆ†å¸ƒ")
        top_dev = dev_mep.groupby("å»ºè¨­å…¬å¸")["å¹´ä½¿ç”¨é‡_è¬"].sum().reset_index().sort_values("å¹´ä½¿ç”¨é‡_è¬", ascending=False).head(20)
        st.write("Top å»ºè¨­å…¬å¸ï¼ˆä¾ç¸½ç”¨é‡ï¼‰")
        st.dataframe(top_dev, use_container_width=True)
        if not dev_mep.empty:
            fig = px.treemap(dev_mep, path=["å»ºè¨­å…¬å¸","æ°´é›»å…¬å¸"], values="å¹´ä½¿ç”¨é‡_è¬", title="å»ºè¨­â†’æ°´é›» Treemapï¼ˆå¹´ä½¿ç”¨é‡_è¬ï¼‰")
            st.plotly_chart(fig, use_container_width=True)
    with t2:
        st.subheader("ç‡Ÿé€ å…¬å¸ä¸‹çš„æ°´é›»ä½¿ç”¨é‡åˆ†å¸ƒ")
        top_con = con_mep.groupby("ç‡Ÿé€ å…¬å¸")["å¹´ä½¿ç”¨é‡_è¬"].sum().reset_index().sort_values("å¹´ä½¿ç”¨é‡_è¬", ascending=False).head(20)
        st.write("Top ç‡Ÿé€ å…¬å¸ï¼ˆä¾ç¸½ç”¨é‡ï¼‰")
        st.dataframe(top_con, use_container_width=True)
        if not con_mep.empty:
            fig = px.treemap(con_mep, path=["ç‡Ÿé€ å…¬å¸","æ°´é›»å…¬å¸"], values="å¹´ä½¿ç”¨é‡_è¬", title="ç‡Ÿé€ â†’æ°´é›» Treemapï¼ˆå¹´ä½¿ç”¨é‡_è¬ï¼‰")
            st.plotly_chart(fig, use_container_width=True)

# -------- Tab 5: æ°´é›»ç«¶çˆ­ --------
with tab5:
    st.subheader("æ°´é›»ä¹‹é–“çš„ç«¶çˆ­å¼·åº¦ï¼ˆåŒä¸€ç‡Ÿé€ å…¬å¸ä¸­çš„å…±ç¾ï¼Œæ¬Šé‡=è©²ç‡Ÿé€ ç¾¤çµ„çš„å¹´ä½¿ç”¨é‡ç¸½å’Œï¼‰")
    if not mep_competition.empty:
        fig = px.imshow(mep_competition, aspect="auto", title="æ°´é›»Ã—æ°´é›» å…±ç¾ç†±åŠ›åœ–ï¼ˆåŠ æ¬Šï¼‰")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç”Ÿæˆæ°´é›»å…±ç¾çŸ©é™£ã€‚")
    st.caption("åœ¨åŒä¸€ç‡Ÿé€ å…¬å¸åº•ä¸‹åŒæ™‚å‡ºç¾çš„æ°´é›»è¦–ç‚ºç«¶çˆ­è€…ï¼Œç¾¤çµ„æ¬Šé‡æ¡ç”¨è©²ç¾¤çµ„å¹´ä½¿ç”¨é‡ç¸½å’Œã€‚")

# -------- Tab 6: ç¶“éŠ·ç«¶åˆ --------
with tab6:
    st.subheader("ç¶“éŠ·å•†ä¹‹é–“çš„ç«¶åˆå¼·åº¦ï¼ˆåŒä¸€æ°´é›»å…¬å¸ï¼›å¼·åº¦=å¹´ä½¿ç”¨é‡_è¬ Ã— min(é…æ¯”i, é…æ¯”j)ï¼‰")
    if not dealer_comp.empty:
        fig = px.imshow(dealer_comp, aspect="auto", title="ç¶“éŠ·å•†Ã—ç¶“éŠ·å•† ç«¶åˆç†±åŠ›åœ–ï¼ˆåŠ æ¬Šï¼‰")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç”Ÿæˆç¶“éŠ·ç«¶åˆçŸ©é™£ã€‚")
    st.caption("åŒä¸€æ°´é›»å…¬å¸è‹¥åŒæ™‚èˆ‡å¤šå®¶ç¶“éŠ·å•†åˆä½œï¼Œå½¼æ­¤è¦–ç‚ºç«¶çˆ­è€…ï¼›é‡ç–Šå¼·åº¦æ¡ min(é…æ¯”i, é…æ¯”j) ä¹˜ä»¥è©²æ°´é›»çš„å¹´ä½¿ç”¨é‡ã€‚")

st.markdown("---")
st.subheader("â¬‡ï¸ åŒ¯å‡º")
# åŒ¯å‡ºä¸»è¦çµæœ
output = io.BytesIO()
with pd.ExcelWriter(output, engine="openpyxl") as writer:
    df_raw.to_excel(writer, index=False, sheet_name="åŸå§‹è³‡æ–™")
    df.to_excel(writer, index=False, sheet_name="ä¸»æª”(å›ºå®šæ¬„ä½å‘½å)")
    rel.to_excel(writer, index=False, sheet_name="é—œä¿‚æ˜ç´°")
    ratio_check.to_excel(writer, index=False, sheet_name="é…æ¯”æª¢æŸ¥")
    top_ratio.to_excel(writer, index=False, sheet_name="å–®ä¸€ä¾è³´æª¢æŸ¥")
    dev_top.to_excel(writer, index=False, sheet_name="å»ºè¨­->ç¶“éŠ· Top3")
    con_top.to_excel(writer, index=False, sheet_name="ç‡Ÿé€ ->ç¶“éŠ· Top3")
    dev_mep.to_excel(writer, index=False, sheet_name="å»ºè¨­->æ°´é›» åˆ†å¸ƒ")
    con_mep.to_excel(writer, index=False, sheet_name="ç‡Ÿé€ ->æ°´é›» åˆ†å¸ƒ")
st.download_button(
    "ä¸‹è¼‰ Excelï¼ˆå¤šå·¥ä½œè¡¨ï¼‰",
    data=output.getvalue(),
    file_name="relations_dashboard_full.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)
